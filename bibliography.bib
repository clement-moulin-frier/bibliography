% This file was created with JabRef 2.7b.
% Encoding: UTF-8

@INPROCEEDINGS{Abramson1970,
  author = {A Abramson and L Lisker},
  title = {Discrimination along the voicing continuum: cross language tests},
  booktitle = {6th Int Congr of Phonetic Science. Prague: Academia},
  year = {1970},
  pages = {569-573},
  owner = {clement},
  timestamp = {2010.05.14}
}

@INPROCEEDINGS{Abry2003,
  author = {Abry, C.},
  title = {[b]-[d]-[g] as a universal triangle as acoustically optimal as [i]-[a]-[u]},
  booktitle = {Proceedings of the 15th international congress of phonetic sciences,
	Barcelona},
  year = {2003},
  pages = {727–-730},
  owner = {clement},
  timestamp = {2010.07.22}
}

@INPROCEEDINGS{Abry2003_SpF_SiF,
  author = {Abry, Christian and Vilain, Anne},
  title = {{"When the Speech frame (SpF) meets the Sign frame (SiF): Interfacing
	the syllable and the word within the foot"}},
  booktitle = {{"Ontogeny and phylogeny of syllable organization: The frame-content
	theory and other approaches", Satellite conference to the 15th International
	Congress of Phonetic Sciences}},
  year = {2003},
  address = {Barcelone, Espagne},
  affiliation = {Institut de la communication parl{\'e}e - ICP},
  audience = {internationale },
  hal_id = {hal-00264479},
  language = {Anglais},
  owner = {clement},
  timestamp = {2012.10.09},
  url = {http://hal.archives-ouvertes.fr/hal-00264479}
}

@ARTICLE{Abry2004,
  author = {C. Abry and A. Vilain and J.-L. Schwartz},
  title = {Vocalize to Localize ? A call for better crosstalk between auditory
	and visual communication systems researchers},
  journal = {Interaction Studies : social behaviour and communication in biological
	and artificial systems},
  year = {2004},
  volume = {5(3)},
  pages = {313--325},
  owner = {Clément},
  timestamp = {2008.02.05}
}

@ARTICLE{arbib2009invention,
  author = {Arbib, MA},
  title = {{Invention and community in the emergence of language: A perspective
	from new sign languages}},
  journal = {Foundations in evolutionary cognitive neuroscience: Introduction
	to the discipline},
  year = {2009},
  pages = {117--52},
  owner = {clement},
  timestamp = {2010.06.03}
}

@ARTICLE{Arbib_pathways:2010,
  author = {Arbib, M A},
  title = {Mirror System Activity for Action and Language is Embedded in the
	Integration of Dorsal \& Ventral Pathways},
  journal = {Brain and Language},
  year = {2010},
  volume = {112},
  pages = {12--24},
  owner = {clement},
  timestamp = {2012.10.23}
}

@ARTICLE{Arbib2005,
  author = {Michael A. Arbib},
  title = {Interweaving protosign and protospeech: Further developments beyond
	the mirror},
  journal = {Interaction Studies},
  year = {2005},
  volume = {6},
  pages = {145--171},
  abstract = {We distinguish “language readiness” (biological) from “having language”
	(cultural) and outline a hypothesis for the evolution of the language-ready
	brain and language involving seven stages: S1: grasping; S2: a mirror
	system for grasping; S3: a simple imitation system for grasping,
	shared with the common ancestor of human and chimpanzee; S4: a complex
	imitation system for grasping; S5: protosign, breaking through the
	fixed repertoire of primate vocalizations to yield an open repertoire
	for communication; S6: protospeech, the open-ended production and
	perception of sequences of vocal gestures, without these sequences
	constituting a full language; and S7: a process of cultural evolution
	in Homo sapiens yielding full human languages. The present paper
	will examine the subhypothesis that protosign {(S5)} formed a scaffolding
	for protospeech {(S6),} but that the two interacted with each other
	in supporting the evolution of brain and body that made Homo sapiens
	“language-ready”.},
  doi = {10.1075/is.6.2.02arb},
  keywords = {1, Language Evolution, Mirror System, Protosign, Protospeech},
  shorttitle = {Interweaving protosign and protospeech}
}

@ARTICLE{arbib_monkey-like_2005,
  author = {Michael A Arbib},
  title = {From monkey-like action recognition to human language: an evolutionary
	framework for neurolinguistics},
  journal = {{Behavioral} {and} {Brain} {Sciences}},
  year = {2005},
  volume = {28},
  pages = {105---167},
  shorttitle = {From monkey-like action recognition to human language}
}

@INPROCEEDINGS{arbib_recognizing_2009,
  author = {Michael A Arbib and Clément {Moulin-Frier}},
  title = {Recognizing speech in a novel accent: The motor theory of speech
	perception reframed.},
  booktitle = {{CRLMB} Distinguished Lecture Series},
  year = {2009},
  address = {Montreal, Quebec Canada},
  note = {Département Parole et Cognition},
  abstract = {Part 1 offers a novel computational model of how a listener comes
	to understand the speech of someone speaking the listener's native
	language with a foreign accent. While involving a number of simplifications
	(which we discuss), we suggest that the core tenet of the model is
	a useful approximation: the listener uses hypotheses about the word
	the speaker is currently uttering to update probabilities linking
	the sound produced by the speaker to phonemes in the native language
	repertoire of the listener. This task seems to fly directly in the
	face of the basic hypothesis of the motor theory of speech perception,
	namely that we perceive the speech of another in terms of a motor
	representation of that speech. We thus assess claims for and against
	the motor theory of speech perception and the relevance of mirror
	neurons in terms of the present model of recognizing speech in a
	novel accent, earlier models of the adaptive formation of mirror
	neurons for grasping, and work emphasizing that the mirror system
	is only one part of a larger system for neurolinguistics processing.}
}

@ARTICLE{Asada2009ITAMD,
  author = {Asada, Minoru and Hosoda, Koh and Kuniyoshi, Yasuo and Ishiguro,
	Hiroshi and Inui, Toshio and Yoshikawa, Yuichiro and Ogino, Masaki
	and Yoshida, Chisato},
  title = {Cognitive developmental robotics: a survey},
  journal = {IEEE Transactions on Autonomous Mental Development},
  year = {2009},
  volume = {1},
  pages = {12-34},
  number = {1},
  abstract = {Cognitive developmental robotics (CDR) aims to provide new understanding
	of how human's higher cognitive functions develop by means of a synthetic
	approach that devel- opmentally constructs cognitive functions. The
	core idea of CDR is ``physical embodiment'' that enables information
	structuring through interactions with the environment, including
	other agents. The idea is shaped based on the hypothesized development
	model of human cognitive functions from body representation to social
	behavior. Along with the model, studies of CDR and related works
	are introduced, and discussion on the model and future issues are
	argued.},
  bdsk-file-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAeIAAAAAAeIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMgG0jtIKwAAAAhh0BJBc2FkYTIwMDlJVEFNRC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGHLyCQzmQAAAAAAAAAAAAEABAAACSAAAAAAAAAAAAAAAAAAAAADcGRmAAAQAAgAAMgGthsAAAARAAgAAMgkF3kAAAABABwACGHQAGommAAIXGQACFxhAAhPqQAISroAAJI/AAIAXE1hY2ludG9zaCBIRDpVc2VyczptYWk6RG9jdW1lbnRzOlJlY2hlcmNoZTpCaWJpb2dyYXBoaWU6T3RoZXJzV3JpdGluZzpwZGY6QXNhZGEyMDA5SVRBTUQucGRmAA4AJgASAEEAcwBhAGQAYQAyADAAMAA5AEkAVABBAE0ARAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAT1VzZXJzL21haS9Eb2N1bWVudHMvUmVjaGVyY2hlL0JpYmlvZ3JhcGhpZS9PdGhlcnNXcml0aW5nL3BkZi9Bc2FkYTIwMDlJVEFNRC5wZGYAABMAAS8AABUAAgAK//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECRPdGhlcnNXcml0aW5nL3BkZi9Bc2FkYTIwMDlJVEFNRC5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKAChgKIAo0ClgKhAqUCswK6AsMC6gLvAvIC/wMEAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAxY=},
  bdsk-url-1 = {http://www.er.ams.eng.osaka-u.ac.jp/Paper/paper-jp.html},
  cited-by = {Sasamoto09c},
  date-added = {2010-05-27 14:31:55 +0200},
  date-modified = {2011-04-19 21:49:10 +0200},
  keywords = {Cognitive Developmental Robotics, Development Model, Synthetic Approach},
  owner = {clement},
  rating = {4},
  timestamp = {2012.06.30},
  url = {http://www.er.ams.eng.osaka-u.ac.jp/Paper/paper-jp.html}
}

@ARTICLE{Atkinson2011,
  author = {Quentin D. Atkinson},
  title = {Phonemic Diversity Supports a Serial Founder Effect Model of Language
	Expansion from Africa},
  journal = {Science},
  year = {2011},
  volume = {332},
  pages = {346 --349},
  number = {6027},
  month = apr,
  abstract = {Human genetic and phenotypic diversity declines with distance from
	Africa, as predicted by a serial founder effect in which successive
	population bottlenecks during range expansion progressively reduce
	diversity, underpinning support for an African origin of modern humans.
	Recent work suggests that a similar founder effect may operate on
	human culture and language. Here I show that the number of phonemes
	used in a global sample of 504 languages is also clinal and fits
	a serial founder{\textendash}effect model of expansion from an inferred
	origin in Africa. This result, which is not explained by more recent
	demographic history, local language diversity, or statistical non-independence
	within language families, points to parallel mechanisms shaping genetic
	and linguistic diversity and supports an African origin of modern
	human languages.},
  doi = {10.1126/science.1199295},
  owner = {clement},
  timestamp = {2011.05.05}
}

@ARTICLE{Baranes2012RAS,
  author = {Baranes, A. and Oudeyer, Pierre-Yves},
  title = {Active Learning of Inverse Models with Intrinsically Motivated Goal
	Exploration in Robots},
  journal = {Robotics and Autonomous Systems},
  year = {2012},
  owner = {clement},
  timestamp = {2012.06.30}
}

@INPROCEEDINGS{Baranes2010_IROS,
  author = {Baranes, A. and Oudeyer, P-Y.},
  title = {Intrinsically Motivated Goal Exploration for Active Motor Learning
	in Robots: a Case Study},
  booktitle = {Proceedings of IEEE/RSJ International Conference on Intelligent Robots
	and Systems (IROS 2010), Taipei, Taiwan},
  year = {2010},
  owner = {clement},
  timestamp = {2013.06.21}
}

@ARTICLE{Baron-Cohen1985,
  author = {S {Baron-Cohen} and {AM} Leslie and U Frith},
  title = {Does the autistic child have a "theory of mind"?},
  journal = {Cognition},
  year = {1985},
  volume = {21},
  pages = {37--46},
  number = {1},
  month = oct,
  issn = {0010-0277},
  keywords = {tom}
}

@CONFERENCE{Barto04,
  author = {Barto, A and Singh, S and Chenatez, N.},
  title = {Intrinsically Motivated Learning of Hierarchical Collections of Skills},
  booktitle = {Proc. 3rd Int. Conf. Dvp. Learn.},
  year = {2004},
  pages = {112-119},
  address = {San Diego, CA},
  date-added = {2010-11-15 17:03:15 +0100},
  date-modified = {2011-09-08 00:00:47 +0200},
  owner = {clement},
  timestamp = {2012.10.23}
}

@ARTICLE{Berlyne54,
  author = {Berlyne, D. E.},
  title = {A theory of human curiosity},
  journal = {British Journal of Psychology},
  year = {1954},
  volume = {45},
  pages = {180-191},
  date-added = {2011-06-23 12:20:27 +0200},
  date-modified = {2011-06-23 12:21:01 +0200},
  owner = {clement},
  timestamp = {2012.10.23}
}

@INPROCEEDINGS{Berrah1996,
  author = {Berrah, Ahmed-Reda and Herv\'{e} Glotin and Rafael Laboissi\`{e}re
	and Pierre Bessi\`{e}re and L.-J. Bo\"{e}},
  title = {From Form to Formation of Phonetic Structures: An evolutionary computing
	perspective},
  booktitle = {ICML '96 workshop on Evolutionary Computing and Machine Learning},
  year = {1996},
  editor = {Terry Fogarty and Gilles Venturini},
  pages = {23--29},
  address = {Bari},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INCOLLECTION{Berrah99,
  author = {{Ahmed-Reda} Berrah and Rafael Laboissière},
  title = {{SPECIES:} An Evolutionary Model for the Emergence of Phonetic Structures
	in an Artificial Society of Speech Agents},
  booktitle = {Advances in Artificial Life},
  year = {1999},
  pages = {674--678},
  abstract = {This paper addresses the emergence of a common phonetic code in a
	society of communicating speech agents using evolutionary techniques.
	Predictions for the large vowel systems of the world’s languages
	using the Maximum Use of Available distinctive Features {(MUAF)}
	principle are discussed. Simulations of the use of supplementary
	phonetic features in large vowel systems are presented. These experimental
	results show how simple local rules of interaction between speaking
	agents are sufficient to explain some of the universal characteristics
	of the phonological structure of the world’s languages.},
  shorttitle = {{SPECIES}}
}

@PHDTHESIS{BerrahThese,
  author = {{Ahmed-Réda} Berrah},
  title = {Evolution d'une société artificielle d'agents de parole : un modéle
	pour l'émergence des structures phonétiques},
  school = {Institut National Polytechnique de Grenoble},
  year = {1998},
  abstract = {Un des grands enjeux de l'étude de la Communication Parlée est la
	justification des tendances universelles des systèmes phonologiques
	des langues du monde. En effet, il s'agit d'expliquer les principes
	gouvernant la distribution des briques de base qui permettent la
	construction du langage. Ces éléments sonores sont désignés par le
	nom de phonèmes. Les travaux présentés dans cette thèse s'inscrivent
	dans ce cadre de recherche. Nous avons utilisé une approche novatrice
	qui consiste en la simulation d'une société d'agents communicants.
	Le but est d'analyser dans quelle mesure un code linguistique commun
	est établi dans une telle société par le jeu de la communication
	parlée, et dans quelle mesure également les inventaires phonétiques
	émergent des principes d'interaction entre agents communicants. Nous
	avons développé un modèle d'échanges perceptifs de voyelles au sein
	d'une communauté d'agents de parole. Ce modèle, appelé ESPECE, a
	été validé à l'issue d'une application à la prédiction des systèmes
	vocaliques. Les résultats des simulations se sont avérés encourageants
	suite à leur confrontation aux données connues sur les inventaires
	phonétiques des langues du monde. En outre, le cadre de simulation
	ESPECE a été étendu en vue de la mise en oeuvre du principe du MUAF
	(Maximum Use of Available distinctive Features). Ce principe permet
	d'expliquer l'apparition de traits supplémentaires dans les larges
	systèmes vocaliques.},
  owner = {clement},
  timestamp = {2010.06.10}
}

@BOOK{bessiere2013_book,
  title = {Bayesian Programming},
  publisher = {CRC Press},
  year = {2013},
  author = {Bessi{\`e}re, Pierre and Mazer, Emmanuel and Ahuactzin, Juan Manuel
	and Mekhnacha, Kamel},
  owner = {clement},
  timestamp = {2013.12.30}
}

@ARTICLE{deBoer2000,
  author = {Bart de Boer},
  title = {Self-organization in vowel systems},
  journal = {Journal of Phonetics},
  year = {2000},
  volume = {28},
  pages = {441--465},
  number = {4},
  month = oct,
  abstract = {This paper presents a computer simulation of the emergence of vowel
	systems in a population of agents. The agents (small computer programs
	that operate autonomously) are equipped with a realistic articulatory
	synthesizer, a model of human perception and the ability to imitate
	and learn sounds they hear. It is shown that due to the interactions
	between the agents and due to self-organization, realistic vowel
	repertoires emerge. This happens under a large number of different
	parameter settings and therefore seems to be a very robust phenomenon.
	The emerged vowel systems show remarkable similarities with the vowel
	systems found in human languages. It is argued that self-organization
	probably plays an important role in determining the vowel inventories
	of human languages and that innate predispositions are probably not
	necessary to explain the universal tendencies of human vowel systems.},
  doi = {10.1006/jpho.2000.0125},
  issn = {0095-4470}
}

@ARTICLE{Boer2010,
  author = {de Boer, Bart and Zuidema, Willem },
  title = {Multi-Agent Simulations of the Evolution of Combinatorial Phonology},
  journal = {Adaptive Behavior},
  year = {2010},
  volume = {18},
  pages = {141--154},
  number = {2},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@MISC{Praat,
  author = {Boersma, Paul \& Weenink, David (2012).},
  title = {Praat: doing phonetics by computer [Computer program]},
  howpublished = {\url{http://www.praat.org/}},
  year = {2012},
  owner = {clement},
  timestamp = {2012.07.01}
}

@ARTICLE{Bohland2006,
  author = {Jason W. Bohland and Frank H. Guenther},
  title = {An {fMRI} investigation of syllable sequence production},
  journal = {{NeuroImage}},
  year = {2006},
  volume = {32},
  pages = {821--841},
  number = {2},
  month = aug,
  abstract = {Fluent speech comprises sequences that are composed from a finite
	alphabet of learned words, syllables, and phonemes. The sequencing
	of discrete motor behaviors has received much attention in the motor
	control literature, but relatively little has been focused directly
	on speech production. In this paper, we investigate the cortical
	and subcortical regions involved in organizing and enacting sequences
	of simple speech sounds. Sparse event-triggered functional magnetic
	resonance imaging {(fMRI)} was used to measure responses to preparation
	and overt production of non-lexical three-syllable utterances, parameterized
	by two factors: syllable complexity and sequence complexity. The
	comparison of overt production trials to preparation only trials
	revealed a network related to the initiation of a speech plan, control
	of the articulators, and to hearing one's own voice. This network
	included the primary motor and somatosensory cortices, auditory cortical
	areas, supplementary motor area {(SMA),} the precentral gyrus of
	the insula, and portions of the thalamus, basal ganglia, and cerebellum.
	Additional stimulus complexity led to increased engagement of the
	basic speech network and recruitment of additional areas known to
	be involved in sequencing non-speech motor acts. In particular, the
	left hemisphere inferior frontal sulcus and posterior parietal cortex,
	and bilateral regions at the junction of the anterior insula and
	frontal operculum, the {SMA} and {pre-SMA,} the basal ganglia, anterior
	thalamus, and the cerebellum showed increased activity for more complex
	stimuli. We hypothesize mechanistic roles for the extended speech
	production network in the organization and execution of sequences
	of speech sounds.},
  doi = {10.1016/j.neuroimage.2006.04.173},
  issn = {1053-8119},
  keywords = {{fMRI,} Language, Motor control, Sequencing, Speech production}
}

@ARTICLE{Bonaiuto2007,
  author = {James Bonaiuto and Edina Rosta and Michael Arbib},
  title = {Extending the mirror neuron system model, I: Audible actions and
	invisible grasps},
  journal = {Biological Cybernetics},
  year = {2007},
  volume = {96},
  pages = {9{\textendash}38},
  month = feb,
  note = {{ACM} {ID:} 1229746},
  abstract = {The paper introduces mirror neuron system {II} {(MNS2),} a new version
	of the {MNS} model {(Oztop} and Arbib in Biol Cybern 87 (2):116{\textendash}140,
	2002) of action recognition learning by mirror neurons of the macaque
	brain. The new model uses a recurrent architecture that is biologically
	more plausible than that of the original model. Moreover, {MNS2}
	extends the capacity of the model to address data on audio-visual
	mirror neurons and on the response of mirror neurons when the target
	object was recently visible but is currently hidden.},
  doi = {10.1007/s00422-006-0110-8},
  issn = {0340-1200},
  keywords = {biology and genetics, design, modeling methodologies},
  owner = {clement},
  shorttitle = {Extending the mirror neuron system model, I},
  timestamp = {2011.05.04}
}

@ARTICLE{Boe2000,
  author = {Bo{\"e}, L.J. and Vallée, N. and Badin, P. and Schwartz, J.L. and
	Abry, C.},
  title = {Tendencies in phonological structures: the influence of substance
	on form},
  journal = {Bulletin de la Communication Parlée},
  year = {2000},
  volume = {5},
  pages = {35--55},
  owner = {clement},
  timestamp = {2011.04.20}
}

@INCOLLECTION{Boe2008,
  author = {Bo{\"e}, L.-J. and Bessi{\`e}re, P. and Ladjili, N. and Audibert,
	N. },
  title = {Simple combinatorial considerations challenge {R}uhlen's mother tongue
	theory},
  booktitle = {The syllable in speech production},
  publisher = {Laurence Erlbaum Associates},
  year = {2008},
  editor = {Barbara L. Davis and Krisztina Zajdo},
  pages = {63--92},
  address = {New York},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Boe_Schwartz_2011_FDL,
  author = {Bo{\"e}, Louis-Jean and Schwartz, Jean-Luc and Granat, Jean and Heim,
	Jean-Louis and Serrurier, Antoine and Badin, Pierre and Captier,
	Guillaume and Bessi{\`e}re, Pierre},
  title = {{L'{\'e}mergence de la parole : Aspects historiques et {\'e}pist{\'e}mologiques
	d'une nouvelle r{\'e}articulation}},
  journal = {Faits de Langues},
  year = {2011},
  volume = {37},
  pages = {15-67},
  abstract = {{L'article s'int{\'e}resse au th{\`e}me de l'exception et des universaux
	linguistiques au niveau des tendances g{\'e}n{\'e}rales des structures
	phonologiques dans les langues du monde. S'appuyant sur les r{\'e}sultats
	d{\'e}j{\`a} obtenus dans le domaine des syst{\`e}mes vocaliques
	(plus les voyelles sont distinctes, plus elles ont de chance de survivre),
	l'article soul{\`e}ve le probl{\`e}me des consonnes qui semblent
	ne pas ob{\'e}ir {\`a} ce principe de distinctivit{\'e} acoustique
	maximale. Pour int{\'e}grer les structures vocaliques et consonantiques
	dans une th{\'e}orie plus g{\'e}n{\'e}rale, l'article utilise des
	r{\'e}sultats mis en {\'e}vidence dans les communications en situation
	de handicap auditif et/ou visuel, afin de montrer que les syst{\`e}mes
	consonantiques semblent se constituer sur la base d'un principe de
	distinctivit{\'e} bimodale acoustique et visuelle.}},
  affiliation = {Pr{\'e}histoire et Pal{\'e}oanthropologie , Grenoble Images Parole
	Signal Automatique - GIPSA-lab , Laboratoire de biom{\'e}canique
	- LB , Laboratoire d'Anatomie , Laboratoire de Physiologie de la
	Perception et de l'Action - LPPA},
  audience = {nationale },
  hal_id = {hal-00640388},
  language = {Fran{\c c}ais},
  owner = {clement},
  timestamp = {2013.12.31},
  url = {http://hal.archives-ouvertes.fr/hal-00640388}
}

@INPROCEEDINGS{Boe1999,
  author = {{Louis-Jean} Bo{\"e}},
  title = {Vowel spaces of newly-born infants and adults consequences for ontogenesis
	and phylogenesis},
  booktitle = {14th Internation Congress of Phonetic Sciences},
  year = {1999},
  pages = {2501--2504},
  owner = {clement},
  timestamp = {2011.04.14}
}

@ARTICLE{Brochu_2010_bayes_opt_tut,
  author = {Eric Brochu and Vlad M. Cora and Nando de Freitas},
  title = {A Tutorial on Bayesian Optimization of Expensive Cost Functions,
	with Application to Active User Modeling and Hierarchical Reinforcement
	Learning},
  journal = {CoRR},
  year = {2010},
  volume = {abs/1012.2599},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://arxiv.org/abs/1012.2599},
  owner = {clement},
  timestamp = {2013.12.31}
}

@ARTICLE{browman_articulatory_1992,
  author = {C P Browman and L Goldstein},
  title = {Articulatory phonology: an overview},
  journal = {Phonetica},
  year = {1992},
  volume = {49},
  pages = {155--180},
  number = {3-4},
  note = {{PMID:} 1488456},
  abstract = {An overview of the basic ideas of articulatory phonology is presented,
	along with selected examples of phonological patterning for which
	the approach seems to provide a particularly insightful account.
	In articulatory phonology, the basic units of phonological contrast
	are gestures, which are also abstract characterizations of articulatory
	events, each with an intrinsic time or duration. Utterances are modeled
	as organized patterns (constellations) of gestures, in which gestural
	units may overlap in time. The phonological structures defined in
	this way provide a set of articulatorily based natural classes. Moreover,
	the patterns of overlapping organization can be used to specify important
	aspects of the phonological structure of particular languages, and
	to account, in a coherent and general way, for a variety of different
	types of phonological variation. Such variation includes allophonic
	variation and fluent speech alternations, as well as 'coarticulation'
	and speech errors. Finally, it is suggested that the gestural approach
	clarifies our understanding of phonological development, by positing
	that prelinguistic units of action are harnessed into (gestural)
	phonological structures through differentiation and coordination.},
  issn = {0031-8388},
  keywords = {Female, Humans, Male, Phonetics, Speech, Speech Production Measurement},
  shorttitle = {Articulatory phonology}
}

@ARTICLE{browman_articulatory_1989,
  author = {Catherine P. Browman and Louis Goldstein},
  title = {Articulatory Gestures as Phonological Units},
  journal = {Phonology},
  year = {1989},
  volume = {6},
  pages = {201--251},
  number = {02},
  abstract = {We have argued that dynamically defined articulatory gestures are
	the appropriate units to serve as the atoms of phonological representation.
	Gestures are a natural unit, not only because they involve task-oriented
	movements of the articulators, but because they arguably emerge as
	prelinguistic discrete units of action in infants. The use of gestures,
	rather than constellations of gestures as in Root nodes, as basic
	units of description makes it possible to characterise a variety
	of language patterns in which gestural organisation varies. Such
	patterns range from the misorderings of disordered speech through
	phonological rules involving gestural overlap and deletion to historical
	changes in which the overlap of gestures provides a crucial explanatory
	element.},
  doi = {10.1017/S0952675700001019}
}

@ARTICLE{Browman1986,
  author = {Catherine P. Browman and Louis M. Goldstein},
  title = {Towards an Articulatory Phonology},
  journal = {Phonology Yearbook},
  year = {1986},
  volume = {3},
  pages = {219--252},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Bessiere_1998_1,
  author = {{B}essière, {P}ierre and {D}edieu, {E}ric and {L}ebeltel, {O}livier
	and {M}azer, {E}mmanuel and {M}ekhnacha, {K}amel},
  title = {{I}nterpr{\'e}tation versus {D}escription ({I}) : {P}roposition pour
	une th{\'e}orie probabiliste des syst{\`e}mes cognitifs sensori-moteurs},
  journal = {{I}ntellectica },
  year = {1999},
  volume = {26-27 },
  pages = {pp 257-311 }
}

@ARTICLE{Bessiere_1998_2,
  author = {{B}essière, {P}ierre and {D}edieu, {E}ric and {L}ebeltel, {O}livier
	and {M}azer, {E}mmanuel and {M}ekhnacha, {K}amel},
  title = {{I}nterpr{\'e}tation ou {D}escription ({II}) : {F}ondements math{\'e}matiques
	de l'approche {F}+{D}},
  journal = {{I}ntellectica },
  year = {1998},
  volume = {26-27 },
  pages = {p. 313-336 }
}

@INPROCEEDINGS{Boe1995,
  author = {{B}o{\"e}, {L}ouis-{J}ean and Gabioud, B. and Perrier, P. },
  title = {Speech maps interactive plant ``{SMIP}''},
  booktitle = {Proceedings of the {XIII}th International Congress of Phonetic Sciences
	},
  year = {1995},
  pages = {426--429},
  address = {Stockholm, Sweden},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@BOOK{calinon2009robotPbD,
  title = {Robot Programming by Demonstration},
  publisher = {CRC},
  year = {2009},
  author = {Calinon, Sylvain},
  owner = {clement},
  timestamp = {2013.03.16}
}

@BOOK{Cheney1992,
  title = {How Monkeys See the World: Inside the Mind of Another Species},
  publisher = {University of Chicago Press},
  year = {1992},
  author = {Dorothy L. Cheney and Robert M. Seyfarth},
  month = apr,
  isbn = {9780226102467},
  owner = {clement},
  shorttitle = {How Monkeys See the World},
  timestamp = {2011.01.19}
}

@ARTICLE{Cheney1982,
  author = {Dorothy L. Cheney and Robert M. Seyfarth},
  title = {How vervet monkeys perceive their grunts: Field playback experiments},
  journal = {Animal Behaviour},
  year = {1982},
  volume = {30},
  pages = {739--751},
  number = {3},
  month = aug,
  abstract = {Free-ranging vervet monkeys grunt to each other in a variety of social
	situations: when approaching a dominant or subordinate individual,
	when moving into a new area of their range, or when observing another
	group. Like other non-human primate vocalizations, these grunts have
	traditionally been interpreted as a single, highly variable call
	that reflects the arousal state of the signaller. Field playback
	experiments suggest, however, that what humans initially perceive
	as one grunt the monkeys perceive as at least four. Each grunt carries
	a specific meaning that seems to depend more on its acoustic properties
	than on the context in which it occurs. Results suggest that the
	vocalizations given by monkeys during social interactions may function
	in a rudimentary representational manner, as if to designate objects
	or events in the external world.},
  doi = {10.1016/S0003-3472(82)80146-2},
  issn = {0003-3472},
  owner = {clement},
  shorttitle = {How vervet monkeys perceive their grunts},
  timestamp = {2011.01.19}
}

@ARTICLE{Chistovich1980,
  author = {Chistovich, L.A.},
  title = {{Auditory Processing of Speech.}},
  journal = {Language and Speech},
  year = {1980},
  volume = {23},
  pages = {67--73},
  number = {1},
  owner = {clement},
  timestamp = {2010.07.27}
}

@BOOK{Chomsky1985,
  title = {Règles et représentations. .},
  year = {1985},
  editor = {Paris, Flammarion [tr. 
	
	 fr. de Rules and representations, New York, Columbia University Press
	
	
	 House, 1980]},
  author = {Chomsky, Noam},
  owner = {clement},
  timestamp = {2011.05.05}
}

@BOOK{Chomsky1965,
  title = {Aspects of the theory of syntax},
  publisher = {MIT Press},
  year = {1965},
  author = {Noam Chomsky},
  address = {Cambridge, MA},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Christiansen2003,
  author = {Morten H Christiansen and Simon Kirby},
  title = {Language evolution: Consensus and controversies},
  journal = {Trends in Cognitive Sciences},
  year = {2003},
  volume = {7},
  pages = {300---307},
  owner = {clement},
  shorttitle = {Language evolution},
  timestamp = {2011.05.05}
}

@INPROCEEDINGS{Clements2003a,
  author = {Clements, N.},
  title = {Feature economy as a phonological universal},
  booktitle = {Proceedings of the 15th International Congress of Phonetic Sciences,
	Barcelona},
  year = {2003},
  volume = {[CD ROM]},
  pages = {371--374},
  owner = {clement},
  timestamp = {2011.05.04}
}

@ARTICLE{Clements2003b,
  author = {Clements, N.},
  title = {Feature economy in sound systems},
  journal = {Phonology},
  year = {2003},
  volume = {3},
  pages = {287--333},
  owner = {clement},
  timestamp = {2011.05.04}
}

@ARTICLE{cohn1996active,
  author = {Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  title = {Active learning with statistical models},
  journal = {Journal of Artificial Intelligence Research},
  year = {1996},
  volume = {4},
  pages = {129--145},
  owner = {clement},
  timestamp = {2013.03.14}
}

@BOOK{Corballis2002,
  title = {From hand to mouth: The origins of language},
  publisher = {Princeton University Press},
  year = {2002},
  author = {Corballis, M. C.},
  address = {Princeton, NJ},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@BOOK{csikszentmihalyi1997creativity,
  title = {Creativity: Flow and the Psychology of Discovery and Invention},
  publisher = {HarperCollins},
  year = {1997},
  author = {Csikszentmihalyi, M.},
  isbn = {9780060928209},
  lccn = {lc96004116},
  owner = {clement},
  timestamp = {2012.10.04}
}

@ARTICLE{COLAS:2010:HAL-00530356:1,
  author = {{C}olas, {F}rancis and {D}iard, {J}ulien and {B}essiere, {P}ierre},
  title = { {C}ommon bayesian models for common cognitive issues},
  journal = {{A}cta {B}iotheoretica },
  year = {2010},
  volume = {58 },
  pages = {191-216 },
  number = {2-3 },
  abstract = {{H}ow can an incomplete and uncertain model of the environment be
	used to perceive, infer, decide and act efﬁciently? {T}his is the
	challenge that both living and artiﬁcial cognitive systems have to
	face. {S}ymbolic logic is, by its nature, unable to deal with this
	question. {T}he subjectivist approach to probability is an extension
	to logic that is designed speciﬁcally to face this challenge. {I}n
	this paper, we review a number of frequently encountered cognitive
	issues and cast them into a common {B}ayesian formalism. {T}he concepts
	we review are ambiguities, fusion, multimodality, conﬂicts, modularity,
	hierarchies and loops. {F}irst, each of these concepts is introduced
	brieﬂy using some examples from the neuroscience, psychophysics or
	robotics literature. {T}hen, the concept is formalized using a template
	{B}ayesian model. {T}he assumptions and common features of these
	models, as well as their major differences, are outlined and discussed.},
  affiliation = {{E}ldgen{\"o}ssische {T}echnische {H}ochschule {Z}{\"u}rich - {ETH}
	{Z}{\"u}rich - {ETH} {Z}urich - {L}aboratoire de psychologie et neurocognition
	- {LPNC} - {CNRS} : {UMR}5105 - {U}niversit{\'e} {P}ierre {M}end{\`e}s-{F}rance
	- {G}renoble {II} - {U}niversit{\'e} {J}oseph {F}ourier - {G}renoble
	{I} - {U}niversit{\'e} de {S}avoie - {L}aboratoire d'{I}nformatique
	de {G}renoble - {LIG} - {CNRS} : {UMR}5217 - {INRIA} - {U}niversit{\'e}
	{P}ierre {M}end{\`e}s-{F}rance - {G}renoble {II} - {U}niversit{\'e}
	{J}oseph {F}ourier - {G}renoble {I} - {I}nstitut {P}olytechnique
	de {G}renoble - {E}-{MOTION} - {INRIA} {R}h{\^o}ne-{A}lpes / {LIG}
	{L}aboratoire d'{I}nformatique de {G}renoble - {INRIA} - {U}niversit{\'e}
	{J}oseph {F}ourier - {G}renoble {I} - {U}niversit{\'e} {P}ierre {M}end{\`e}s-{F}rance
	- {G}renoble {II} - {I}nstitut {N}ational {P}olytechnique de {G}renoble
	- {INPG} - {CNRS} : {UMR}5217 },
  audience = {internationale },
  doi = {10.1007/s10441-010-9101-1 },
  hal_id = {hal-00530356},
  language = {{A}nglais},
  owner = {clement},
  timestamp = {2011.03.01}
}

@ARTICLE{Davis_Mermelstein_1980,
  author = {Davis, S. and Mermelstein, P.},
  title = {{Comparison of parametric representations for monosyllabic word recognition
	in continuously spoken sentences}},
  journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
  year = {1980},
  volume = {28},
  pages = {357--366},
  number = {4},
  month = aug,
  abstract = {{Several parametric representations of the acoustic signal were compared
	with regard to word recognition performance in a syllable-oriented
	continuous speech recognition system. The vocabulary included many
	phonetically similar monosyllabic words, therefore the emphasis was
	on the ability to retain phonetically significant acoustic information
	in the face of syntactic and duration variations. For each parameter
	set (based on a mel-frequency cepstrum, a linear frequency cepstrum,
	a linear prediction cepstrum, a linear prediction spectrum, or a
	set of reflection coefficients), word templates were generated using
	an efficient dynamic warping method, and test data were time registered
	with the templates. A set of ten mel-frequency cepstrum coefficients
	computed every 6.4 ms resulted in the best performance, namely 96.5
	percent and 95.0 percent recognition with each of two speakers. The
	superior performance of the mel-frequency cepstrum coefficients may
	be attributed to the fact that they better represent the perceptually
	relevant aspects of the short-term speech spectrum.}},
  citeulike-article-id = {1273618},
  citeulike-linkout-0 = {http://dx.doi.org/10.1109/TASSP.1980.1163420},
  citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163420},
  doi = {10.1109/TASSP.1980.1163420},
  institution = {Signal Technology, Inc., Santa Barbara, CA},
  issn = {0096-3518},
  keywords = {mfcc, speech},
  owner = {clement},
  posted-at = {2007-07-30 22:57:59},
  priority = {2},
  publisher = {IEEE},
  timestamp = {2012.07.01},
  url = {http://dx.doi.org/10.1109/TASSP.1980.1163420}
}

@BOOK{Deci85,
  title = {Intrinsic Motivation and self-determination in human behavior},
  publisher = {Plenum Press},
  year = {1985},
  author = {Deci, E.L. and Ryan, Richard M.},
  address = {New York},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Dempster1977,
  author = {A. P. Dempster and N. M. Laird and D. B. Rubin},
  title = {Maximum Likelihood from Incomplete Data via the {EM} Algorithm},
  journal = {Journal of the Royal Statistical Society. Series B {(Methodological)}},
  year = {1977},
  volume = {39},
  pages = {1--38},
  number = {1},
  month = jan,
  abstract = {{{\textless}p{\textgreater}A} broadly applicable algorithm for computing
	maximum likelihood estimates from incomplete data is presented at
	various levels of generality. Theory showing the monotone behaviour
	of the likelihood and convergence of the algorithm is derived. Many
	examples are sketched, including missing value situations, applications
	to grouped, censored or truncated data, finite mixture models, variance
	component estimation, hyperparameter estimation, iteratively reweighted
	least squares and factor analysis.{\textless}/p{\textgreater}},
  issn = {00359246},
  owner = {clement},
  timestamp = {2011.04.06}
}

@PHDTHESIS{Diard2003,
  author = {Diard, Julien},
  title = {La carte bayésienne : un modèle probabiliste hiérarchique pour la
	navigation en robotique mobile},
  school = {{I}nstitut {N}ational {P}olytechnique de {G}renoble - {INPG}},
  year = {2003},
  owner = {clement}
}

@ARTICLE{diard:10,
  author = {Julien Diard and Estelle Gilet and {\'E}va Simonin and Pierre Bessi{\`e}re},
  title = {Incremental Learning of Bayesian Sensorimotor Models: from Low-level
	Behaviors to the Large-scale Structure of the Environment},
  journal = {Connection Science},
  year = {2010},
  volume = {22},
  pages = {291--312},
  number = {4},
  owner = {clement},
  timestamp = {2013.12.30}
}

@ARTICLE{diehl_speech_2004,
  author = {Randy L Diehl and Andrew J Lotto and Lori L Holt},
  title = {Speech perception},
  journal = {Annual Review of Psychology},
  year = {2004},
  volume = {55},
  pages = {149--179},
  abstract = {This chapter focuses on one of the first steps in comprehending spoken
	language: How do listeners extract the most fundamental linguistic
	elements-consonants and vowels, or the distinctive features which
	compose them-from the acoustic signal? We begin by describing three
	major theoretical perspectives on the perception of speech. Then
	we review several lines of research that are relevant to distinguishing
	these perspectives. The research topics surveyed include categorical
	perception, phonetic context effects, learning of speech and related
	nonspeech categories, and the relation between speech perception
	and production. Finally, we describe challenges facing each of the
	major theoretical perspectives on speech perception.},
  doi = {10.1146/annurev.psych.55.090902.142028},
  issn = {0066-4308},
  keywords = {Humans, Phonetics, Psychological Theory, Sound Spectrography, Speech
	Perception, Speech Production Measurement, Time Factors}
}

@ARTICLE{Dominey_2002_conceptual,
  author = {Peter Ford Dominey},
  title = {Conceptual Grounding in Simulation Studies of Language Acquisition},
  journal = {Evolution of Communication},
  year = {2002},
  volume = {4},
  pages = {57--85},
  number = {1},
  owner = {clement},
  timestamp = {2013.12.30}
}

@PHDTHESIS{DuceyKaufmann_these,
  author = {{D}ucey{-}{K}aufmann, {V}irginie},
  title = {Le cadre de la parole et le cadre du signe : un rendez-vous développemental},
  school = {{U}niversit{\'e} {S}tendhal - {G}renoble {III}},
  year = {2007},
  month = {01},
  note = {{D}{\'e}partement {P}arole et {C}ognition },
  abstract = {{N}otre hypoth{\`e}se de travail est qu'il existerait un rendez-vous
	d{\'e}veloppemental entre ce que nous nommons le cadre de la parole
	et le cadre du signe. {T}andis que le cadre de la parole ({S}peech
	{F}rame) s'{\'e}tablit sous la forme du babillage canonique, vers
	7 mois, le cadre du signe ({S}ign {F}rame) se manifeste tout d'abord
	sous la forme du pointage dit imp{\'e}ratif vers 9 mois, avant de
	donner lieu au pointage dit d{\'e}claratif. {C}e dernier appara{\^i}t
	avec les premiers mots, tandis que le cadre de la parole permet {\`a}
	ce moment-l{\`a} de coproduire (coarticuler) voyelle et consonne
	({S}ussman et al. 1999). {L}es places respectives des ingr{\'e}dients
	de ce rendez-vous d{\'e}veloppemental autour du premier mot restent
	encore {\`a} explorer.{D}ans la pr{\'e}sente contribution, nous avons
	voulu tester l'existence d'un rapport harmonique entre cadre de la
	parole et cadre du signe. {P}our cela, il nous a fallu tout d'abord
	obtenir la distribution des fr{\'e}quences de babillage, puis celle
	des dur{\'e}es des pointers. {N}os r{\'e}sultats sur 6 sujets, suivis
	sur 12 mois, montrent qu'avec un mode de babillage {\`a} 3{H}z et
	des strokes de pointers de 600-700 ms (1.5{H}z), nous pouvons rendre
	compte du gabarit (template) des premiers mots. {E}n effet, ces mots
	«prosodiques» pouvant varier d'une {\`a} deux «syllabes», il est
	n{\'e}cessaire de faire appel {\`a} la notion de pied (foot) comme
	une unit{\'e} de contr{\^o}le m{\'e}trique ancr{\'e}e dans le pointer.
	{C}eci rendra compte des observations courantes dans la litt{\'e}rature
	{\`a} condition qu'au lieu de compter seulement des syllabes/mot,
	on mesure le pas des cycles mandibulaires entrant dans le stroke
	des pointers.},
  affiliation = {{G}renoble {I}mages {P}arole {S}ignal {A}utomatique - {GIPSA}-lab
	- {CNRS} : {UMR}5216 - {U}niversit{\'e} {J}oseph {F}ourier - {G}renoble
	{I} - {U}niversit{\'e} {P}ierre {M}end{\`e}s-{F}rance - {G}renoble
	{II} - {U}niversit{\'e} {S}tendhal - {G}renoble {III} - {I}nstitut
	{P}olytechnique de {G}renoble },
  day = {26},
  hal_id = {tel-00152445},
  keywords = {{C}adre de la parole, {C}adre du signe, babillage, syllabe, pointer
	de l'index, stroke, pied},
  owner = {clement},
  timestamp = {2010.06.11}
}

@ARTICLE{Fadiga2002,
  author = {Fadiga, L. and Craighero, L. and Buccino, G. and Rizzolatti, G.},
  title = {{Speech listening specifically modulates the excitability of tongue
	muscles: a TMS study}},
  journal = {European Journal of Neuroscience},
  year = {2002},
  volume = {15},
  pages = {399--402},
  number = {2},
  owner = {clement},
  publisher = {John Wiley \& Sons},
  timestamp = {2010.08.07}
}

@ARTICLE{Fadiga1995,
  author = {L. Fadiga and L. Fogassi and G. Pavesi and G. Rizzolatti},
  title = {Motor facilitation during action observation: a magnetic stimulation
	study},
  journal = {J Neurophysiol},
  year = {1995},
  volume = {73},
  pages = {2608--2611},
  number = {6},
  shorttitle = {Motor facilitation during action observation}
}

@ARTICLE{Fagg1998,
  author = {Andrew H. Fagg and Michael A. Arbib},
  title = {Modeling parietal-premotor interactions in primate control of grasping},
  journal = {Neural Networks},
  year = {1998},
  volume = {11},
  pages = {1277--1303},
  number = {7-8},
  month = oct,
  abstract = {{{\textless}p{\textgreater}{\textless}br/{\textgreater}Visual} information
	is processed in the posterior parietal cortex for the hypothesized
	purpose of extracting a variety of affordances for the generation
	of motor behavior. The term affordance is used to mean that visual
	cues are mapped directly to parameters that are relevant for motor
	interaction. In this paper, we present the {FARS} model of the cortical
	involvement in grasping, a model which focuses on the interaction
	between anterior intra-parietal area {(AIP)} and premotor area F5.
	The model represents the role of other intra-parietal areas, working
	in concert with inferotemporal cortex and F5, to provide {AIP} with
	a full range of information from which affordances may be derived.
	The model also suggests how task information and other constraints
	may resolve the action opportunities provided by multiple affordances.
	Our model demonstrates not only that posterior parietal cortex is
	a network of interacting subsystems, but also that it functions through
	a pattern of "cooperative computation" with a multiplicity of other
	brain regions. Finally, through the use of several novel tasks, the
	model allows us to make specific predictions regarding neural firing
	patterns at both the single unit and population levels, which aids
	in our further understanding of information encoding in these brain
	regions.{\textless}/p{\textgreater}},
  doi = {10.1016/S0893-6080(98)00047-1},
  issn = {0893-6080},
  keywords = {Affordances, Computational model, Grasping, Neural networks, Parietal
	cortex, Premotor cortex},
  owner = {clement},
  timestamp = {2011.05.04}
}

@ARTICLE{Fowler1986,
  author = {C. A Fowler},
  title = {An event approach to the study of speech perception from a direct-realist
	perspective.},
  journal = {Journal of Phonetics},
  year = {1986},
  volume = {14},
  pages = {3–28},
  number = {1}
}

@BOOK{Frith1995,
  title = {The cognitive neuropsychology of schizophrenia},
  publisher = {Psychology Press},
  year = {1995},
  author = {Christopher D. Frith},
  pages = {188},
  month = jan,
  isbn = {9780863773341}
}

@INPROCEEDINGS{Fukui_2009_waseda_talker,
  author = {Fukui, K. and Ishikawa, Y. and Ohno, K. and Sakakibara, N. and Honda,
	M. and Takanishi, A.},
  title = {Three dimensional tongue with liquid sealing mechanism for improving
	resonance on an anthropomorphic talking robot},
  booktitle = {Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International
	Conference on},
  year = {2009},
  pages = {5456-5462},
  abstract = {We have developed a new, three dimensional vocal tract mechanical
	model for an anthropomorphic talking robot WT-7R (Waseda Talker No.
	7 Refined), to improve the resonance of the vocal tract. The Waseda
	Talker robot series aims to reproduce the human speech mechanism
	with three-dimensional accuracy. The tongue of the previous model,
	WT-7 (Waseda Talker No. 7), was made of rigid links and covered with
	a thermoplastic rubber (Septon). This mechanism could deform the
	tongue shape and work as a part of the vocal tract, however, the
	cover thickness was not sufficient enough to prevent sound leakage,
	and did not have sufficient resonance. As a result, the produced
	sounds were unclear. To resolve this problem, the inner area of the
	tongue was filled with liquid. We experimented to select the filling
	liquid which is minimizes damage to the Septon cover and provides
	adequate resonance characteristics. The ethylene glycol was selected
	because it does little damage to the Septon and is relatively non-flammable.
	An oil seal and liquid gasket prevent leakage into the robot. WT-7
	also has problems with its tongue link deformation range and open
	lip control range-these problems were also addressed. The improvements
	made the vowel production of WT-7R clearer than that of the previous
	robot, and the bandwidth of the formant peak in spectral analysis
	became sharper.},
  doi = {10.1109/IROS.2009.5353983},
  keywords = {intelligent robots;speech processing;Septon cover;Waseda Talker robot;anthropomorphic
	talking robot;liquid sealing mechanism;spectral analysis;three dimensional
	tongue;three dimensional vocal tract mechanical model;Anthropomorphism;Anti-freeze;Filling;Humans;Resonance;Robots;Rubber;Shape;Speech;Tongue},
  owner = {clement},
  timestamp = {2014.01.06}
}

@ARTICLE{Galantucci2005,
  author = {Galantucci, B},
  title = {An Experimental Study of the Emergence of Human Communication},
  journal = {Cognitive Science},
  year = {2005},
  volume = {29},
  pages = {737--767},
  owner = {clement},
  timestamp = {2011.05.04}
}

@ARTICLE{galantucci_motor_2006,
  author = {Bruno Galantucci and Carol A. Fowler and M. T. Turvey},
  title = {The motor theory of speech perception reviewed},
  journal = {Psychonomic Bulletin \& Review},
  year = {2006},
  volume = {13},
  pages = {361--377},
  number = {3},
  abstract = {More than 50 years after the appearance of the motor theory of speech
	perception, it is timely to evaluate its three main claims that (1)
	speech processing is special, (2) perceiving speech is perceiving
	gestures, and (3) the motor system is recruited for perceiving speech.
	We argue that to the extent that it can be evaluated, the first claim
	is likely false. As for the second claim, we review findings that
	support it and argue that although each of these findings may be
	explained by alternative accounts, the claim provides a single coherent
	account. As for the third claim, we review findings in the literature
	that support it at different levels of generality and argue that
	the claim anticipated a theme that has become widespread in cognitive
	science.},
  doi = {VL - 13}
}

@ARTICLE{Gell-Mann2011,
  author = {Murray Gell-Mann and Merritt Ruhlen },
  title = {The origin and evolution of word order},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2011},
  volume = {108},
  pages = {17290--17295},
  number = {42},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Gentilucci2006,
  author = {Gentilucci, M. and Corballis, M. C.},
  title = {From manual gesture to speech: A gradual transition},
  journal = {Neuroscience and Biobehavioral Reviews},
  year = {2006},
  volume = {30},
  number = {949--960},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INCOLLECTION{Goldin-Meadow2003,
  author = {Goldin-Meadow, S. and Butcher, C.},
  title = {Pointing toward two-word speech in young children},
  booktitle = {Pointing: Where language, culture, and cognition meet},
  publisher = {Lawrence Erlbaum Associates},
  year = {2003},
  editor = {S. Kita},
  pages = {85--107},
  address = {Mahwah, N.J.},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INPROCEEDINGS{Grabski2010,
  author = {Krystyna Grabski and Laurent Lamalle and {Jean-Luc} Schwartz and
	Coriandre Vilain and Nathalie Vallée and Irène Tropres and Monica
	Baciu and Jean-François Le Bas and Marc Sato},
  title = {Corrélats neuroanatomiques des systèmes de perception et de production
	des voyelles du Français},
  booktitle = {28e Journées {d'Etudes} sur la Parole, {JEP'2010}},
  year = {2010},
  address = {Avignon France},
  abstract = {In this paper, we show how some properties of human language could
	emerge from the primitive deixis function. For this aim, we model
	a society of sensori-motor agents able to produce vocalizations and
	to point to objects in their environnement. We show how principles
	of the Dispersion Theory [6] and the Quantal Theory [13] could emerge
	from the interaction between these agents.},
  keywords = {Evolutionnary Linguistic, Language Emergence; Bayesian Modeling; Cognitive
	Robotics; {Multi-Agents} Systems},
  owner = {clement},
  timestamp = {2010.07.22}
}

@ARTICLE{Grezes1998,
  author = {Grezes, J.},
  title = {{Top down effect of strategy on the perception of human biological
	motion: A PET investigation}},
  journal = {Cognitive Neuropsychology},
  year = {1998},
  volume = {15},
  pages = {553--582},
  number = {6},
  owner = {clement},
  publisher = {Psychology Press},
  timestamp = {2010.08.07}
}

@INPROCEEDINGS{Griffiths2005,
  author = {Griffiths, T. L. and Kalish, M. L.},
  title = {A Bayesian view of language evolution by iterated learning},
  booktitle = {27th Annual Conference of the Cognitive Science Society},
  year = {2005},
  abstract = {Models of language evolution have demonstrated how
	
	aspects of human language, such as compositionality,
	
	can arise in populations of interacting agents. This paper
	
	analyzes how languages change as the result of a
	
	particular form of interaction: agents learning from one
	
	another. We show that, when the learners are rational
	
	Bayesian agents, this process of iterated learning converges
	
	to the prior distribution over languages assumed
	
	by those learners. The rate of convergence is set by
	
	the amount of information conveyed by the data seen
	
	by each generation; the less informative the data, the
	
	faster the process converges to the prior.},
  file = {:D\:\\Documents\\LMD\\THESE\\BIBLIO\\Griffiths05_ A Bayesian view of language evolution by iterated learning.pdf:PDF},
  keywords = {linguistique évolutionnaire, modèle bayésien, chaine de markov},
  owner = {Clément},
  review = {A FINIR DE LIRE
	
	
	Les agents cherchent à estimer la relation entre "significations"
	et "énoncés" (meaning and utterance) par un apprentissage bayésien
	itératif. Apparemment assez loin de ce que l'on fait.
	
	
	Article plus complet :
	
	Griffiths, T. L. and Kalish, M. L. (2007) Language evolution by iterated
	learning with Bayesian agents. Cognitive Science, 31(3):441--480.},
  timestamp = {2007.11.19}
}

@ARTICLE{Grezes2003,
  author = {J. Grèzes and J. L. Armony and J. Rowe and R. E. Passingham},
  title = {Activations related to "mirror" and "canonical" neurones in the human
	brain: an {fMRI} study},
  journal = {{NeuroImage}},
  year = {2003},
  volume = {18},
  pages = {928--937},
  number = {4},
  month = apr,
  abstract = {In the macaque monkey ventral premotor cortex {(F5),} "canonical neurones"
	are active when the monkey observes an object and when the monkey
	grasps that object. In the same area, "mirror neurones" fire both
	when the monkey observes another monkey grasping an object and when
	the monkey grasps that object. We used event-related {fMRI} to investigate
	where in the human brain activation can be found that reflects both
	canonical and mirror neuronal activity. There was activation in the
	intraparietal and ventral limbs of the precentral sulcus when subjects
	observed objects and when they executed movements in response to
	the objects (canonical neurones). There was activation in the dorsal
	premotor cortex, the intraparietal cortex, the parietal operculum
	{(SII),} and the superior temporal sulcus when subjects observed
	gestures (mirror neurones). Finally, activations in the ventral premotor
	cortex and inferior frontal gyrus (area 44) were found when subjects
	imitated gestures and executed movements in response to objects.
	We suggest that in the human brain, the ventral limb of the precentral
	sulcus may form part of the area designated F5 in the macaque monkey.
	It is possible that area 44 forms an anterior part of F5, though
	anatomical studies suggest that it may be a transitional area between
	the premotor and prefrontal cortices.},
  doi = {10.1016/S1053-8119(03)00042-9},
  issn = {1053-8119},
  keywords = {Canonical neurons, {fMRI,} Inferior frontal gyrus, Mirror neurons,
	Parietal cortex, Premotor cortex},
  shorttitle = {Activations related to "mirror" and "canonical" neurones in the human
	brain}
}

@ARTICLE{Guenther2006,
  author = {Frank H. Guenther},
  title = {Cortical interactions underlying the production of speech sounds},
  journal = {Journal of Communication Disorders},
  year = {2006},
  volume = {39},
  pages = {350--365},
  number = {5},
  month = sep,
  abstract = {Speech production involves the integration of auditory, somatosensory,
	and motor information in the brain. This article describes a model
	of speech motor control in which a feedforward control system, involving
	premotor and primary motor cortex and the cerebellum, works in concert
	with auditory and somatosensory feedback control systems that involve
	both sensory and motor cortical areas. New speech sounds are learned
	by first storing an auditory target for the sound, then using the
	auditory feedback control system to control production of the sound
	in early repetitions. Repeated production of the sound leads to tuning
	of feedforward commands which eventually supplant the feedback-based
	control signals. Although parts of the model remain speculative,
	it accounts for a wide range of kinematic, acoustic, and neuroimaging
	data collected during speech production and provides a framework
	for investigating communication disorders that involve malfunction
	of the cerebral cortex and interconnected subcortical structures.
	Learning outcomes: Readers will be able to: (1) describe several
	types of learning that occur in the sensory-motor system during babbling
	and early speech, (2) identify three neural control subsystems involved
	in speech production, (3) identify regions of the brain involved
	in monitoring auditory and somatosensory feedback during speech production,
	and (4) identify regions of the brain involved in feedforward control
	of speech.},
  doi = {10.1016/j.jcomdis.2006.06.013},
  issn = {0021-9924}
}

@ARTICLE{Guenther1995,
  author = {Frank H. Guenther},
  title = {Speech sound acquisition, coarticulation, and rate effects in a neural
	network model of speech production.},
  journal = {Psychological Review},
  year = {1995},
  volume = {102},
  pages = {594--621},
  number = {3},
  doi = {10.1037/0033-295X.102.3.594},
  issn = {{0033-295X}}
}

@ARTICLE{guenther2006neural,
  author = {Guenther, Frank H and Ghosh, Satrajit S and Tourville, Jason A},
  title = {Neural modeling and imaging of the cortical interactions underlying
	syllable production},
  journal = {Brain and language},
  year = {2006},
  volume = {96},
  pages = {280--301},
  number = {3},
  owner = {clement},
  publisher = {Elsevier},
  timestamp = {2013.03.24}
}

@ARTICLE{guenther_theoretical_1998,
  author = {F H Guenther and M Hampson and D Johnson},
  title = {A theoretical investigation of reference frames for the planning
	of speech movements},
  journal = {Psychological Review},
  year = {1998},
  volume = {105},
  pages = {611--633},
  number = {4},
  month = oct,
  note = {{PMID:} 9830375},
  abstract = {Does the speech motor control system use invariant vocal tract shape
	targets when producing vowels and semivowels? A 4-part theoretical
	treatment favoring models whose only invariant targets are regions
	in auditory perceptual space over models that posit invariant constriction
	targets is presented. Auditory target regions are hypothesized to
	arise during development as an emergent property of neural map formation
	in the auditory system. Furthermore, speech movements are planned
	as trajectories in auditory perceptual space. These trajectories
	are then mapped into articulator movements through a neural mapping
	that allows motor equivalent variability in constriction locations
	and degrees when needed. These hypotheses are illustrated using computer
	simulations of the {DIVA} model of speech acquisition and production.
	Finally, several difficult challenges to proponents of constriction
	theories based on this theoretical treatment are posed.},
  issn = {{0033-295X}},
  keywords = {Humans, Models, Theoretical, Speech}
}

@BOOK{Haeckel1896,
  title = {The evolution of man, Vol. 1. .},
  publisher = {D. Appleton},
  year = {1896},
  author = {Haeckel, E.},
  owner = {clement},
  timestamp = {2012.10.13}
}

@ARTICLE{Harnad1990,
  author = {Stevan Harnad},
  title = {The symbol grounding problem},
  journal = {Physica D: Nonlinear Phenomena},
  year = {1990},
  volume = {42},
  pages = {335--346},
  number = {1-3},
  month = jun,
  abstract = {{{\textless}p{\textgreater}{\textless}br/{\textgreater}There} has
	been much discussion recently about the scope and limits of purely
	symbolic models of the mind and about the proper role of connectionism
	in cognitive modeling. This paper describes the "symbol grounding
	problem": How can the semantic interpretation of a formal symbol
	system be made intrinsic to the system, rather than just parasitic
	on the meanings in our heads? How can the meanings of the meaningless
	symbol tokens, manipulated solely on the basis of their (arbitrary)
	shapes, be grounded in anything but other meaningless symbols? The
	problem is analogous to trying to learn Chinese from a {Chinese/Chinese}
	dictionary alone. A candidate solution is sketched: Symbolic representations
	must be grounded bottom-up in nonsymbolic representations of two
	kinds: (1) iconic representations, which are analogs of the proximal
	sensory projections of distal objects and events, and (2) categorical
	representations, which are learned and innate feature detectors that
	pick out the invariant features of object and event categories from
	their sensory projections. Elementary symbols are the names of these
	object and event categories, assigned on the basis of their (nonsymbolic)
	categorical representations. Higher-order (3) symbolic representations,
	grounded in these elementary symbols, consist of symbol strings describing
	category membership relations (e.g. {"An} X is a Y that is {Z").{\textless}br/{\textgreater}Connectionism}
	is one natural candidate for the mechanism that learns the invariant
	features underlying categorical representations, thereby connecting
	names to the proximal projections of the distal objects they stand
	for. In this way connectionism can be seen as a complementary component
	in a hybrid nonsymbolic/symbolic model of the mind, rather than a
	rival to purely symbolic modeling. Such a hybrid model would not
	have an autonomous symbolic "module," however; the symbolic functions
	would emerge as an intrinsically "dedicated" symbol system as a consequence
	of the bottom-up grounding of categories' names in their sensory
	representations. Symbol manipulation would be governed not just by
	the arbitrary shapes of the symbol tokens, but by the nonarbitrary
	shapes of the icons and category invariants in which they are grounded.{\textless}/p{\textgreater}},
  doi = {10.1016/0167-2789(90)90087-6},
  issn = {0167-2789},
  owner = {clement},
  timestamp = {2011.04.28}
}

@ARTICLE{Hickok2009,
  author = {Gregory Hickok},
  title = {Eight Problems for the Mirror Neuron Theory of Action Understanding
	in Monkeys and Humans},
  journal = {Journal of Cognitive Neuroscience},
  year = {2009},
  volume = {21},
  pages = {1229--1243},
  number = {7},
  abstract = {The discovery of mirror neurons in macaque frontal cortex has sparked
	a resurgence of interest in motor/embodied theories of cognition.
	This critical review examines the evidence in support of one of these
	theories, namely, that mirror neurons provide the basis of action
	understanding. It is argued that there is no evidence from monkey
	data that directly tests this theory, and evidence from humans makes
	a strong case against the position.},
  doi = {10.1162/jocn.2009.21189}
}

@ARTICLE{Hickok2000,
  author = {Gregory Hickok and Peter Erhard and Jan Kassubek and A. Kate {Helms-Tillery}
	and Susan {Naeve-Velguth} and John P. Strupp and Peter L. Strick
	and Kamil Ugurbil},
  title = {A functional magnetic resonance imaging study of the role of left
	posterior superior temporal gyrus in speech production: implications
	for the explanation of conduction aphasia},
  journal = {Neuroscience Letters},
  year = {2000},
  volume = {287},
  pages = {156--160},
  number = {2},
  abstract = {Conduction aphasia, characterized by good auditory comprehension and
	fluent but disordered speech production, is classically viewed as
	a disconnection syndrome. We review recent evidence which suggests
	that at least one form of conduction aphasia results from damage
	to cortical fields in the left posterior superior temporal gyrus
	which participate not only in speech perception, but also in phonemic
	aspects of speech production. As a test of this hypothesis, we carried
	out a {4T} functional magnetic resonance imaging study in which subjects
	named visually presented objects sub-vocally. Group-based analyses
	showed that a majority of participants showed activation in two regions
	on the dorsal portion of the left posterior superior temporal gyrus.},
  doi = {10.1016/S0304-3940(00)01143-5},
  issn = {0304-3940},
  keywords = {Conduction aphasia, Functional magnetic resonance image, Language,
	Speech production},
  shorttitle = {A functional magnetic resonance imaging study of the role of left
	posterior superior temporal gyrus in speech production}
}

@ARTICLE{hickok_cortical_2007,
  author = {Gregory Hickok and David Poeppel},
  title = {The cortical organization of speech processing},
  journal = {Nat Rev Neurosci},
  year = {2007},
  volume = {8},
  pages = {393--402},
  number = {5},
  month = may,
  doi = {10.1038/nrn2113},
  issn = {{1471-003X}}
}

@ARTICLE{Hickok2004,
  author = {Gregory Hickok and David Poeppel},
  title = {Dorsal and ventral streams: a framework for understanding aspects
	of the functional anatomy of language},
  journal = {Cognition},
  year = {2004},
  volume = {92},
  pages = {67--99},
  number = {1-2},
  month = jun,
  note = {{PMID:} 15037127},
  abstract = {Despite intensive work on language-brain relations, and a fairly impressive
	accumulation of knowledge over the last several decades, there has
	been little progress in developing large-scale models of the functional
	anatomy of language that integrate neuropsychological, neuroimaging,
	and psycholinguistic data. Drawing on relatively recent developments
	in the cortical organization of vision, and on data from a variety
	of sources, we propose a new framework for understanding aspects
	of the functional anatomy of language which moves towards remedying
	this situation. The framework posits that early cortical stages of
	speech perception involve auditory fields in the superior temporal
	gyrus bilaterally (although asymmetrically). This cortical processing
	system then diverges into two broad processing streams, a ventral
	stream, which is involved in mapping sound onto meaning, and a dorsal
	stream, which is involved in mapping sound onto articulatory-based
	representations. The ventral stream projects ventro-laterally toward
	inferior posterior temporal cortex (posterior middle temporal gyrus)
	which serves as an interface between sound-based representations
	of speech in the superior temporal gyrus (again bilaterally) and
	widely distributed conceptual representations. The dorsal stream
	projects dorso-posteriorly involving a region in the posterior Sylvian
	fissure at the parietal-temporal boundary (area Spt), and ultimately
	projecting to frontal regions. This network provides a mechanism
	for the development and maintenance of "parity" between auditory
	and motor representations of speech. Although the proposed dorsal
	stream represents a very tight connection between processes involved
	in speech perception and speech production, it does not appear to
	be a critical component of the speech perception process under normal
	(ecologically natural) listening conditions, that is, when speech
	input is mapped onto a conceptual representation. We also propose
	some degree of bi-directionality in both the dorsal and ventral pathways.
	We discuss some recent empirical tests of this framework that utilize
	a range of methods. We also show how damage to different components
	of this framework can account for the major symptom clusters of the
	fluent aphasias, and discuss some recent evidence concerning how
	sentence-level processing might be integrated into the framework.},
  doi = {10.1016/j.cognition.2003.10.011},
  issn = {0010-0277},
  keywords = {Aphasia, Brain, Humans, Language, Parietal Lobe, Speech Perception,
	Speech Production Measurement, Temporal Lobe},
  shorttitle = {Dorsal and ventral streams}
}

@INPROCEEDINGS{higashimoto2003mechanical,
  author = {Higashimoto, Toshio and Sawada, Hideyuki},
  title = {A mechanical voice system: construction of vocal cords and its pitch
	control},
  booktitle = {International Conference on Intelligent Technologies},
  year = {2003},
  volume = {7624768},
  owner = {clement},
  timestamp = {2014.01.06}
}

@INPROCEEDINGS{hofe2009biomimetic,
  author = {Hofe, Robin and Moore, Roger K},
  title = {Biomimetic vocal tract modeling: preliminary results of vocalization
	experiments},
  booktitle = {Proceedings of Meetings on Acoustics},
  year = {2009},
  volume = {6},
  pages = {060004},
  owner = {clement},
  timestamp = {2014.01.06}
}

@ARTICLE{Holst1954,
  author = {Holst, E.},
  title = {{Relations between the central nervous system and the peripheral
	organs}},
  journal = {British Journal of Animal Behaviour},
  year = {1954},
  volume = {2},
  pages = {89--94},
  owner = {clement},
  timestamp = {2010.08.06}
}

@ARTICLE{howard_messum_motor_control,
  author = {I.S. Howard and P. Messum},
  title = {Modeling the development of pronunciation in infant speech acquisition},
  journal = {Motor Control},
  year = {2011},
  volume = {15(1)},
  pages = {85-117},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Iacoboni1999,
  author = {Marco Iacoboni and Roger P. Woods and Marcel Brass and Harold Bekkering
	and John C. Mazziotta and Giacomo Rizzolatti},
  title = {Cortical Mechanisms of Human Imitation},
  journal = {Science},
  year = {1999},
  volume = {286},
  pages = {2526--2528},
  number = {5449},
  month = dec,
  doi = {10.1126/science.286.5449.2526}
}

@INPROCEEDINGS{ijspeert2002movement,
  author = {Ijspeert, Auke Jan and Nakanishi, Jun and Schaal, Stefan},
  title = {Movement imitation with nonlinear dynamical systems in humanoid robots},
  booktitle = {Robotics and Automation, 2002. Proceedings. ICRA'02. IEEE International
	Conference on},
  year = {2002},
  volume = {2},
  pages = {1398--1403},
  organization = {IEEE},
  owner = {clement},
  timestamp = {2013.03.14}
}

@ARTICLE{ishihara2009caregiver,
  author = {Ishihara, Hisashi and Yoshikawa, Yuichiro and Miura, Katsushi and
	Asada, Minoru},
  title = {How caregiver's anticipation shapes infant's vowel through mutual
	imitation},
  journal = {Autonomous Mental Development, IEEE Transactions on},
  year = {2009},
  volume = {1},
  pages = {217--225},
  number = {4},
  owner = {clement},
  publisher = {IEEE},
  timestamp = {2013.10.18}
}

@BOOK{Jaynes2003,
  title = {Probability Theory: The Logic of Science},
  publisher = {Cambridge University Press},
  year = {2003},
  editor = {G. Larry Bretthorst},
  author = {Edwin T. Jaynes},
  month = {June}
}

@ARTICLE{Kaplan2005,
  author = {Kaplan, F.},
  title = {{Simple models of distributed co-ordination}},
  journal = {Connection Science},
  year = {2005},
  volume = {17},
  pages = {249--270},
  number = {3},
  owner = {clement},
  publisher = {Taylor \& Francis},
  timestamp = {2010.06.14}
}

@CONFERENCE{Kaplan2000,
  author = {Kaplan, F.},
  title = {{Semiotic schemata: Selection units for linguistic cultural evolution}},
  booktitle = {Artificial life VII: proceedings of the seventh International Conference
	on Artificial Life},
  year = {2000},
  pages = {372},
  organization = {The MIT Press},
  owner = {clement},
  timestamp = {2010.06.14}
}

@INCOLLECTION{kaplan:07,
  author = {Kaplan, F. and Oudeyer, P-Y.},
  title = {The progress-drive hypothesis: an interpretation of early imitation},
  booktitle = {Models and mechanisms of imitation and social learning: Behavioural,
	social and communication dimensions},
  publisher = {Cambridge University Press},
  year = {2007},
  editor = {Dautenhahn, K. and Nehaniv, C.},
  date-added = {2013-05-30 19:07:07 +0200},
  date-modified = {2013-05-30 19:07:07 +0200},
  owner = {clement},
  timestamp = {2012.10.23}
}

@ARTICLE{kaplan2007search,
  author = {Kaplan, Frederic and Oudeyer, Pierre-Yves},
  title = {In search of the neural circuits of intrinsic motivation},
  journal = {Frontiers in neuroscience},
  year = {2007},
  volume = {1},
  pages = {225},
  number = {1},
  owner = {clement},
  publisher = {Frontiers Research Foundation},
  timestamp = {2013.03.14}
}

@INCOLLECTION{Kawai_2013_synchro,
  author = {Kawai, Yuji and Park, Jihoon and Horii, Takato and Oshima, Yuji and
	Tanaka, Kazuaki and Mori, Hiroki and Nagai, Yukie and Takuma, Takashi
	and Asada, Minoru},
  title = {Throwing Skill Optimization through Synchronization and Desynchronization
	of Degree of Freedom},
  booktitle = {RoboCup 2012: Robot Soccer World Cup XVI},
  publisher = {Springer Berlin Heidelberg},
  year = {2013},
  editor = {Chen, Xiaoping and Stone, Peter and Sucar, LuisEnrique and Zant,
	Tijn},
  volume = {7500},
  series = {Lecture Notes in Computer Science},
  pages = {178-189},
  doi = {10.1007/978-3-642-39250-4_17},
  isbn = {978-3-642-39249-8},
  owner = {clement},
  timestamp = {2013.12.31},
  url = {http://dx.doi.org/10.1007/978-3-642-39250-4_17}
}

@ARTICLE{Kemp_2008_structural,
  author = {Kemp, C. and Tenenbaum, J. B.},
  title = {The discovery of structural form},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2008},
  volume = {105},
  pages = {10687--10692},
  number = {31},
  owner = {clement},
  timestamp = {2013.12.30}
}

@BOOK{Kent1997,
  title = {The Speech Sciences},
  publisher = {Singular Publishing Group},
  year = {1997},
  author = {Raymond D. Kent},
  month = jan
}

@ARTICLE{Kohler2002,
  author = {Evelyne Kohler and Christian Keysers and M. Alessandra Umilt\`{a}
	and Leonardo Fogassi and Vittorio Gallese and Giacomo Rizzolatti},
  title = {Hearing Sounds, Understanding Actions: Action Representation in Mirror
	Neurons},
  journal = {Science},
  year = {2002},
  volume = {297},
  pages = {846 --848},
  number = {5582},
  __markedentry = {[clement]},
  abstract = {Many object-related actions can be recognized by their sound. We found
	neurons in monkey premotor cortex that discharge when the animal
	performs a specific action and when it hears the related sound. Most
	of the neurons also discharge when the monkey observes the same action.
	These audiovisual mirror neurons code actions independently of whether
	these actions are performed, heard, or seen. This discovery in the
	monkey homolog of Broca's area might shed light on the origin of
	language: audiovisual mirror neurons code abstract contents{\textemdash}the
	meaning of actions{\textemdash}and have the auditory access typical
	of human language to these contents.},
  doi = {10.1126/science.1070311},
  owner = {clement},
  shorttitle = {Hearing Sounds, Understanding Actions},
  timestamp = {2011.05.23}
}

@ARTICLE{Kohonen1990,
  author = {Kohonen, T.},
  title = {{The self-organizing map}},
  journal = {Proceedings of the IEEE},
  year = {1990},
  volume = {78},
  pages = {1464--1480},
  number = {9},
  owner = {clement},
  timestamp = {2010.06.10}
}

@INPROCEEDINGS{Konczak2005,
  author = {J{\"u}rgen Konczak},
  title = {On the notion of motor primitives in humans and robots},
  booktitle = {Proceedings of the Fifth International Workshop on Epigenetic Robotics:
	Modeling Cognitive Development in Robotic Systems},
  year = {2005},
  editor = {Luc Berthouze and Fr{\'e}d{\'e}ric Kaplan and Hideki Kozima and Hiroyuki
	Yano and J{\"u}rgen Konczak and Giorgio Metta and Jacqueline Nadel
	and Giulio Sandini and Georgi Stojanov and Christian Balkenius},
  volume = {123},
  pages = {47--53},
  publisher = {Lund University Cognitive Studies},
  __markedentry = {[clement:]},
  abstract = {This article reviews two reflexive motor patterns in humans: Primitive
	reflexes and motor primitives. Both terms coexist in the literature
	of motor development and motor control, yet they are not synonyms.
	While primitive reflexes are a part of the temporary motor repertoire
	in early ontogeny, motor primitives refer to sets of motor patterns
	that are considered basic units of voluntary motor control thought
	to be present throughout the life-span. The article provides an overview
	of the anatomy and neurophysiology of human reflexive motor patterns
	to elucidate that both concepts are rooted in architecture of the
	spinal cord. I will advocate that an understanding of the human motor
	system that encompasses both primitive reflexes and motor primitives
	as well as the interaction with supraspinal motor centers will lead
	to an appreciation of the richness of the human motor repertoire,
	which in turn seems imperative for designing epigenetic robots and
	highly adaptable human machine interfaces.},
  keywords = {motor primitives, infantile reflexes, infant motor development, developmental
	robot},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Kuhl1982,
  author = {P K Kuhl and D M Padden},
  title = {Enhanced discriminability at the phonetic boundaries for the voicing
	feature in macaques},
  journal = {Perception \& Psychophysics},
  year = {1982},
  volume = {32},
  pages = {542--550},
  number = {6},
  month = dec,
  note = {{PMID:} 7167352},
  issn = {0031-5117},
  keywords = {Animals, Evolution, Female, Language, Macaca, Male, Phonetics, Speech
	Acoustics, Speech Perception}
}

@ARTICLE{Laurent_BBS_commentary,
  author = {Rapha{\"e}l Laurent and Cl\'{e}ment Moulin-Frier and Pierre Bessi\`{e}re
	and Jean-Luc Schwartz and Julien Diard},
  title = {Integrate yes, but what and how?},
  journal = {Behavioral and Brain Sciences (commentary)},
  year = {2013},
  owner = {clement},
  timestamp = {2012.10.05}
}

@ARTICLE{lebeltel_bayesian_2004,
  author = {Olivier Lebeltel and Pierre Bessiere and Julien Diard and Emmanuel
	Mazer},
  title = {Bayesian Robot Programming},
  journal = {Autonomous Robots},
  year = {2004},
  volume = {16},
  pages = {49–79},
  abstract = {We propose a new method to program robots based on Bayesian inference
	and learning. It is called {BRP} for Bayesian Robot Programming.
	The capacities of this programming method are demonstrated through
	a succession of increasingly complex experiments. Starting from the
	learning of simple reactive behaviors, we present instances of behavior
	combination, sensor fusion, hierarchical behavior composition, situation
	recognition and temporal sequencing. This series of experiments comprises
	the steps in the incremental development of a complex robot program.
	The advantages and drawbacks of {BRP} are discussed along with these
	different experiments and summed up as a conclusion. These different
	robotics programs may be seen as an illustration of probabilistic
	programming applicable whenever one must deal with problems based
	on uncertain or incomplete knowledge. The scope of possible applications
	is obviously much broader than robotics.},
  keywords = {architecture, autonomous, Bayesian, computational, control, for, of,
	programming;, robot, robots;, systems, systems;, theory}
}

@ARTICLE{Liberman93,
  author = {A M Liberman},
  title = {Some assumptions about speech and how they changed},
  journal = {Haskins Laboratories Status Report on Speech Research},
  year = {1993},
  volume = {113},
  pages = {1--32},
  owner = {clement},
  timestamp = {2010.06.08}
}

@ARTICLE{liberman_motor_1985,
  author = {A M Liberman and I G Mattingly},
  title = {The motor theory of speech perception revised},
  journal = {Cognition},
  year = {1985},
  volume = {21},
  pages = {1--36},
  number = {1},
  month = oct,
  issn = {0010-0277},
  keywords = {Humans, Psychological Theory, Speech Perception}
}

@ARTICLE{Liljencrants1972,
  author = {Johan Liljencrants and Björn Lindblom},
  title = {Numerical Simulation of Vowel Quality Systems: The Role of Perceptual
	Contrast},
  journal = {Language},
  year = {1972},
  volume = {48},
  pages = {839--862},
  number = {4},
  month = dec,
  abstract = {A numerical model is developed in order to establish the extent to
	which the principle of maximal perceptual contrast can be used in
	phonological theory to explain the phonetic structure of vowel systems.
	Preliminary results obtained with the model indicate that perceptual
	contrast appears to play an important role as a determinant of such
	systems. Therefore, it is likely that this principle (along with
	other factors) should be included among the variables in an explanatory
	phonological theory. However, the incorporation of numerically stated
	conditions on phonological structure appears to presuppose a formalism
	different from that which has developed within current descriptions
	of phonology. Some refinements and extensions of the present framework
	are suggested. It is proposed that predictions of phonological facts
	be derived as consequences of the structure of the mechanisms available
	for human speech communication and the optimization of their use.
	Such an extension would constitute a theory that would be different
	from traditional {'Saussurean'} linguistics in several respects;
	e.g., it would be quantitative, and deliberately substance-based.
	The research reported represents a preliminary attempt to apply such
	a program.},
  issn = {00978507},
  shorttitle = {Numerical Simulation of Vowel Quality Systems}
}

@INCOLLECTION{Lindblom1990a,
  author = {B. Lindblom},
  title = {Explaining phonetic variation: a sketch of the {H\&H} theory},
  booktitle = {Speech production and speech modelling},
  publisher = {Kluwer},
  year = {1990},
  editor = {Hardcastle, W.J. and Marchal, A.},
  pages = {403--439},
  address = {Dordrecht},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INCOLLECTION{Lindblom98,
  author = {B. Lindblom},
  title = {Systemic constraints and adaptive change in the formation of sound
	structure},
  booktitle = {Approaches to the Evolution of Language: Social and Cognitive Bases},
  publisher = {Cambridge University Press},
  year = {1998},
  editor = {Hurford, J. R. and Studdert-Kennedy, M. and Knight C.},
  address = {Cambridge},
  owner = {clement},
  timestamp = {2011.05.04}
}

@INCOLLECTION{Lindblom1986,
  author = {B. Lindblom},
  title = {Phonetic universals in vowel systems},
  booktitle = {Experimental phonology},
  publisher = {Academic Press},
  year = {1986},
  editor = {Ohala, J.J. and Jaeger, J.J.},
  pages = {13--44},
  address = {Orlando, FL},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Lindblom1990,
  author = {Lindblom, B.},
  title = {{On the notion of ‘possible speech sound’}},
  journal = {Journal of phonetics},
  year = {1990},
  volume = {18},
  pages = {135--152},
  number = {2},
  owner = {clement},
  timestamp = {2010.07.22}
}

@CONFERENCE{lindblom1984,
  author = {Lindblom, B.},
  title = {{Can the models of evolutionary biology be applied to phonetic problems}},
  booktitle = {Proceedings of the tenth international congress of phonetic sciences},
  year = {1984},
  pages = {67--81},
  organization = {Foris Pubns USA},
  owner = {clement},
  timestamp = {2010.06.03}
}

@INPROCEEDINGS{lopes2012strategic,
  author = {Lopes, Manuel and Oudeyer, Pierre-Yves},
  title = {The strategic student approach for life-long exploration and learning},
  booktitle = {2012 IEEE International Conference on Development and Learning and
	Epigenetic Robotics (ICDL)},
  year = {2012},
  pages = {1--8},
  organization = {IEEE},
  owner = {clement},
  timestamp = {2013.03.31}
}

@ARTICLE{Lotto2009,
  author = {Andrew J. Lotto and Gregory S. Hickok and Lori L. Holt},
  title = {Reflections on mirror neurons and speech perception},
  journal = {Trends in Cognitive Sciences},
  year = {2009},
  volume = {13},
  pages = {110--114},
  number = {3},
  doi = {10.1016/j.tics.2008.11.008},
  issn = {13646613}
}

@ARTICLE{MacNeilage2001,
  author = {P.F. MacNeilage and B.L. Davis},
  title = {Motor mechanisms in speech ontogeny: Phylogenetic, neurobiological
	and linguistic implications},
  journal = {Current Opinion in Neurobiology},
  year = {2001},
  volume = {11},
  pages = {696--700},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{macneilage98,
  author = {P. F. MacNeilage},
  title = {The frame/content theory of evolution of speech production},
  journal = {Behavioral and Brain Sciences},
  year = {1998},
  volume = {21},
  pages = {499-511},
  keywords = {speech, language, evolution, communication, neuropsychology},
  owner = {clement},
  timestamp = {2010.06.11}
}

@ARTICLE{macneilage2000,
  author = {Peter F. MacNeilage and Barbara L. Davis},
  title = {On the origin of internal structure of word forms},
  journal = {Science},
  year = {2000},
  volume = {288},
  pages = {527-531},
  doi = {10.1126/science.288.5465.527},
  owner = {clement},
  timestamp = {2010.06.11}
}

@BOOK{Maddieson1984,
  title = {Patterns of Sounds},
  publisher = {Cambridge University Press},
  year = {1984},
  author = {Maddieson},
  month = nov,
  isbn = {0521265363}
}

@ARTICLE{Maddieson1989,
  author = {Ian Maddieson and Kristin Precoda},
  title = {Updating {UPSID}},
  journal = {The Journal of the Acoustical Society of America},
  year = {1989},
  volume = {86},
  pages = {S19},
  number = {S1},
  month = nov,
  doi = {10.1121/1.2027403}
}

@ARTICLE{Maeda1989,
  author = {Maeda, S.},
  title = {{Compensatory articulation during speech: Evidence from the analysis
	and synthesis of vocal tract shapes using an articulatory model}},
  journal = {Speech production and speech modelling},
  year = {1989},
  volume = {55},
  pages = {131--149},
  owner = {clement},
  timestamp = {2010.07.26}
}

@ARTICLE{Manser2004,
  author = {Manser, Marta B. and Fletcher, Lindsay B },
  title = {Vocalize to localize: A test on functionally referential alarm calls},
  journal = {Interaction Studies},
  year = {2004},
  volume = {5},
  pages = {327--344},
  number = {3},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{mcgeer1990passive,
  author = {McGeer, Tad},
  title = {Passive dynamic walking},
  journal = {the international journal of robotics research},
  year = {1990},
  volume = {9},
  pages = {62--82},
  number = {2},
  owner = {clement},
  publisher = {Sage Publications},
  timestamp = {2013.12.30}
}

@ARTICLE{McGurk76,
  author = {Harry {McGurk} and John {MacDonald}},
  title = {Hearing lips and seeing voices},
  journal = {Nature},
  year = {1976},
  volume = {264},
  pages = {746--748},
  number = {5588},
  month = dec,
  doi = {10.1038/264746a0}
}

@ARTICLE{miura2012vowel,
  author = {Miura, Katsushi and Yoshikawa, Yuichiro and Asada, Minoru},
  title = {Vowel acquisition based on an auto-mirroring bias with a less imitative
	caregiver},
  journal = {Advanced Robotics},
  year = {2012},
  volume = {26},
  pages = {23--44},
  number = {1-2},
  owner = {clement},
  publisher = {Taylor \& Francis},
  timestamp = {2013.12.11}
}

@ARTICLE{Moineau2005,
  author = {Suzanne Moineau and Nina F. Dronkers and Elizabeth Bates},
  title = {Exploring the Processing Continuum of {Single-Word} Comprehension
	in Aphasia},
  journal = {J Speech Lang Hear Res},
  year = {2005},
  volume = {48},
  pages = {884--896},
  number = {4},
  month = aug,
  abstract = {This study investigated the vulnerability of lexical processing in
	individuals with aphasia. Though classical teaching of aphasia syndromes
	holds that people with Broca's aphasia have intact comprehension
	at the single-word level, the nature and extent of this purported
	sparing were explored under suboptimal processing conditions. A combination
	of acoustic distortions (low-pass filtering and time compression)
	was used to probe for "break points" in lexical comprehension in
	a group of individuals with aphasia. Results suggest that accurate
	and efficient lexical processing is vulnerable to suboptimal listening
	climates, and that processing under these conditions reveals the
	continuous nature of the impairment of linguistic behaviors observed
	in individuals with aphasia.},
  doi = {10.1044/1092-4388(2005/061)}
}

@PHDTHESIS{Moulin-Frier_2011_PhD_thesis,
  author = {Cl\'{e}ment Moulin-Frier},
  title = {Rôle des relations perception-action dans la communication parlée
	et l'émergence des systèmes phonologiques~:étude, modélisation computationnelle
	et simulations},
  school = {Université de Grenoble},
  year = {2011},
  owner = {clement},
  timestamp = {2012.10.05}
}

@MASTERSTHESIS{Moulin-Frier_2007_Master_ScCo,
  author = {Cl\'{e}ment Moulin-Frier},
  title = {Jeux déictiques dans une société d'agents sensori-moteurs en interaction},
  school = {Grenoble-INP},
  year = {2007},
  owner = {clement},
  timestamp = {2012.10.05}
}

@ARTICLE{Moulin-Frier_2013_COSMO,
  author = {Cl\'{e}ment Moulin-Frier and Julien Diard and Jean-Luc Schwartz and
	Pierre Bessi\`{e}re},
  title = {COSMO (``Communicating about Objects using Sensory-Motor Operations''):
	a Bayesian modeling framework for studying speech communication and
	the emergence of phonological systems},
  year = {SUB},
  owner = {clement},
  timestamp = {2012.10.05}
}

@ARTICLE{Moulin-Frier2012_adverse,
  author = {Cl\'{e}ment Moulin-Frier and Rapha\"el Laurent and Pierre Bessi\`{e}re
	and Jean-Luc Schwartz and Julien Diard},
  title = {Adverse conditions improve distinguishability of auditory, motor
	and perceptuo-motor theories of speech perception: an exploratory
	Bayesian modeling study},
  journal = {Language and Cognitive Processes},
  year = {2012},
  volume = {27},
  pages = {1240--1263},
  number = {7--8},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Moulin-Frier_Frontiers_2013,
  author = {Moulin-Frier, Clément and Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
  title = {Self-Organization of Early Vocal Development in Infants and Machines:
	The Role of Intrinsic Motivation},
  journal = {Frontiers in Psychology},
  year = {2013},
  volume = {4},
  number = {1006},
  abstract = {We bridge the gap between two issues in infant development: vocal
	development and intrinsic motivation. We propose and experimentally
	test the hypothesis that general mechanisms of intrinsically motivated
	spontaneous exploration, also called curiosity-driven learning, can
	self-organize developmental stages during early vocal learning. We
	introduce a computational model of intrinsically motivated vocal
	exploration, which allows the learner to autonomously structure its
	own vocal experiments, and thus its own learning schedule, through
	a drive to maximize competence progress. This model relies on a physical
	model of the vocal tract, the auditory system and the agent's motor
	control as well as vocalizations of social peers. We present computational
	experiments that show how such a mechanism can explain the adaptive
	transition from vocal self-exploration with little influence from
	the speech environment, to a later stage where vocal exploration
	becomes influenced by vocalizations of peers. Within the initial
	self-exploration phase, we show that a sequence of vocal production
	stages self-organizes, and shares properties with data from infant
	developmental psychology: the vocal learner first discovers how to
	control phonation, then focuses on vocal variations of unarticulated
	sounds, and finally automatically discovers and focuses on babbling
	with articulated proto-syllables. As the vocal learner becomes more
	proficient at producing complex sounds, imitating vocalizations of
	peers starts to provide high learning progress explaining an automatic
	shift from self-exploration to vocal imitation.},
  doi = {10.3389/fpsyg.2013.01006},
  issn = {1664-1078},
  owner = {clement},
  timestamp = {2013.12.20},
  url = {http://www.frontiersin.org/cognitive_science/10.3389/fpsyg.2013.01006/abstract}
}

@INPROCEEDINGS{Moulin-Frier_Interspeech_2013,
  author = {Cl\'{e}ment Moulin-Frier and Pierre-Yves Oudeyer},
  title = {The role of intrinsic motivations in learning sensorimotor vocal
	mappings: a developmental robotics study},
  booktitle = {{Proceedings of Interspeech}},
  year = {2013},
  pages = {In press},
  address = {Lyon, France},
  audience = {internationale },
  owner = {clement},
  timestamp = {2013.06.23}
}

@INPROCEEDINGS{Moulin-Frier_Oudeyer_2013_ICDL,
  author = {Cl\'{e}ment Moulin-Frier and Pierre-Yves Oudeyer},
  title = {Exploration strategies in developmental robotics: A unified probabilistic
	framework},
  booktitle = {International Conference on Development and Learning, ICDL/Epirob,
	Osaka, Japan},
  year = {2013},
  pages = {1-6},
  abstract = {We present a probabilistic framework unifying two important families
	of exploration mechanisms recently shown to be efficient to learn
	complex non-linear redundant sensorimotor mappings. These two explorations
	mechanisms are: 1) goal babbling, 2) active learning driven by the
	maximization of empirically measured learning progress. We show how
	this generic framework allows to model several recent algorithmic
	architectures for exploration. Then, we propose a particular implementation
	using Gaussian Mixture Models, which at the same time provides an
	original empirical measure of the competence progress. Finally, we
	perform computer simulations on two simulated setups: the control
	of the end effector of a 7-DoF arm and the control of the formants
	produced by an articulatory synthesizer.},
  doi = {10.1109/DevLrn.2013.6652535},
  keywords = {Gaussian processes;end effectors;learning systems;nonlinear systems;probability;speech
	synthesis;7-DoF arm;Gaussian mixture model;active learning;algorithmic
	architecture;articulatory synthesizer;competence progress;complex
	nonlinear redundant sensorimotor mapping;computer simulation;developmental
	robotics;empirically measured learning progress;end effector control;exploration
	mechanism;exploration strategies;formant control;goal babbling;unified
	probabilistic framework;Aerospace electronics;Computational modeling;End
	effectors;Probabilistic logic;Robot sensing systems;Time measurement}
}

@INPROCEEDINGS{Moulin-Frier_Oudeyer_2013_RLDM,
  author = {Cl\'{e}ment Moulin-Frier and Pierre-Yves Oudeyer},
  title = {Learning how to reach various goals by autonomous interaction with
	the environment: unification and comparison of exploration strategies},
  booktitle = {1st Multidisciplinary Conference on Reinforcement Learning and Decision
	Making (RLDM2013), Princeton University, New Jersey.},
  year = {2013},
  pages = {In press},
  owner = {clement},
  timestamp = {2012.10.05}
}

@INPROCEEDINGS{Moulin-Frier_Oudeyer_2012_ICDL,
  author = {Moulin-Frier, C. and Oudeyer, P.-Y.},
  title = {Curiosity-driven phonetic learning},
  booktitle = {2012 IEEE International Conference on Development and Learning and
	Epigenetic Robotics (ICDL)},
  year = {2012},
  pages = {1-8},
  doi = {10.1109/DevLrn.2012.6400583},
  keywords = {speech processing;auditory modalities;auditory-motor inverse model;automatically
	developmental structure;curiosity-driven active goal selection;curiosity-driven
	phonetic learning;intrinsically motivated exploration;intrinsically
	motivated learning;pure curiosity-driven exploration;random goal
	selection;random motor exploration;realistic vocal tract model;Lungs;Manganese;Vibrations},
  owner = {clement},
  timestamp = {2013.06.21}
}

@MASTERSTHESIS{Moulin-Frier_2006_Master_Info,
  author = {Clément {Moulin-Frier}},
  title = {Objets communicants~: la traçabilité},
  school = {Université Joseph Fourier, Grenoble},
  year = {2006},
  owner = {clement},
  timestamp = {2012.10.05}
}

@ARTICLE{Moulin-Frier_BiCy,
  author = {Cl{\'e}ment {Moulin-Frier} and Michael A Arbib},
  title = {Recognizing speech in a novel accent: The motor theory of speech
	perception reframed},
  journal = {Biological Cybernetics},
  year = {2013},
  volume = {107 (4)},
  pages = {421--447},
  owner = {clement},
  publisher = {Springer-Verlag},
  timestamp = {2010.05.15}
}

@INPROCEEDINGS{MoulinFrier_ISSP11,
  author = {Cl{\'e}ment {Moulin-Frier} and Rapha{\"e}l Laurent and Pierre Bessi{\`e}re
	and {Jean-Luc} Schwartz and Julien Diard},
  title = {Noise and inter-speaker variability improve distinguishability of
	auditory, motor and perceptuo-motor theories of speech perception
	: An exploratory Bayesian Modeling study},
  booktitle = {9th International Seminar on Speech Production, {ISSP'11}},
  year = {2011},
  address = {Montral, Canada},
  owner = {clement},
  timestamp = {2011.05.06}
}

@INBOOK{Moulin-Frier_vocoid,
  chapter = {Emergence of articulatory-acoustic systems from deictic interaction
	games in a "Vocalize to Localize" framework},
  title = {Primate communication and human language: Vocalisations, gestures,
	imitation and deixis in humans and non-humans},
  publisher = {Advances in Interaction Studies' series by John Benjamins Pub. Co.},
  year = {2011},
  editor = {Anne Vilain, Jean-Luc Schwartz, Christian Abry \& Jacques Vauclair},
  author = {Clément {Moulin-Frier} and {Jean-Luc} Schwartz and Julien Diard and
	Pierre Bessière},
  owner = {clement},
  timestamp = {2010.05.15}
}

@INPROCEEDINGS{Moulin-Frier2010_miami,
  author = {Clément {Moulin-Frier} and {Jean-Luc} Schwartz and Julien Diard and
	Pierre Bessière},
  title = {A unified theoretical Bayesian model of speech communication},
  booktitle = {1st conference on Applied Digital Human Modeling, Miami, USA},
  year = {2010},
  abstract = {Based on a review of models and theories in speech communication,
	this paper proposes an original Bayesian framework able to express
	each of them in a unified way. This framework allows to selectively
	incorporate motor processes in perception or auditory representations
	in production, thus implementing components of a perceptuo-motor
	link in speech communication processes. This provides a basis for
	future computational works on the joint study of perception, production
	and their coupling in speech communication.},
  keywords = {Speech Communication, Cognitive Bayesian Modeling, Sensory-Motor interaction},
  owner = {clement},
  timestamp = {2010.05.17}
}

@INPROCEEDINGS{moulin-frier_emergence_2008,
  author = {Clément {Moulin-Frier} and {Jean-Luc} Schwartz and Julien Diard and
	Pierre Bessière},
  title = {Emergence of a language through deictic games within a society of
	sensori-motor agents in interaction},
  booktitle = {8th International Seminar on Speech Production, {ISSP'08}},
  year = {2008},
  address = {Strasbourg France},
  note = {Département Parole et Cognition},
  abstract = {Starting from language origins theories, which connect prelinguistic
	primate abilities such as deixis, to modern linguistic systems, we
	seek to let emerge universals of human languages such as dispersion
	principles and the quantal aspect of speech. For this aim, we model
	a society of Bayesian sensory-motor agents, which interact and evolve
	in an environment filled with objects they can identify. We show
	how these agents may converge on a common phonological code for communication.
	This enables us to validate our assumptions and suggest probabilistic
	models of language origins {theories.ISSP}}
}

@INPROCEEDINGS{moulin-frier_emergence_2008-1,
  author = {Clément {Moulin-Frier} and {Jean-Luc} Schwartz and Julien Diard and
	Pierre Bessière},
  title = {Emergence du langage par jeux déictiques dans une société d'agents
	sensori-moteurs en interaction},
  booktitle = {27e Journées {d'Etudes} sur la Parole, {JEP'2008}},
  year = {2008},
  address = {Avignon France},
  note = {Département Parole et Cognition},
  abstract = {In this paper, we show how some properties of human language could
	emerge from the primitive deixis function. For this aim, we model
	a society of sensori-motor agents able to produce vocalizations and
	to point to objects in their environnement. We show how principles
	of the Dispersion Theory [6] and the Quantal Theory [13] could emerge
	from the interaction between these agents.},
  keywords = {Evolutionnary Linguistic, Language Emergence; Bayesian Modeling; Cognitive
	Robotics; {Multi-Agents} Systems}
}

@INPROCEEDINGS{moulin-frier_emergence_2008-2,
  author = {Clément {Moulin-Frier} and {Jean-Luc} Schwartz and Julien Diard and
	Pierre Bessière},
  title = {Emergence of a language through deictic games within a society of
	sensori-motor agents in interaction},
  booktitle = {International Workshop on {"Speech} and Face to Face Communication"},
  year = {2008},
  address = {Grenoble France},
  note = {Département Parole et Cognition}
}

@PHDTHESIS{Menard_These,
  author = {Ménard, Lucie},
  title = {Production et perception des voyelles au cours de la croissance du
	conduit vocal :
	
	variabilité, invariance et normalisation},
  school = {Université Stendhal, Grenoble},
  year = {2002},
  owner = {clement},
  timestamp = {2011.05.01}
}

@ARTICLE{Menard2008,
  author = {Ménard, L. and Schwartz, J.L. and Aubin, J.},
  title = {Invariance and variability in the production of the height feature
	in French vowels},
  journal = {Speech Communication},
  year = {2008},
  volume = {50},
  pages = {14--28},
  owner = {clement},
  timestamp = {2011.05.06}
}

@ARTICLE{NGuyen_2013_quasimetric,
  author = {N'Guyen, Steve and Moulin-Frier, Cl{\'e}ment and Droulez, Jacques},
  title = {{Decision Making under Uncertainty: A Quasimetric Approach}},
  journal = {PLoS ONE},
  year = {2013},
  volume = {8},
  pages = {e83411},
  number = {12 },
  month = Dec,
  abstract = {{We propose a new approach for solving a class of discrete decision
	making problems under uncertainty with positive cost. This issue
	concerns multiple and diverse fields such as engineering, economics,
	artificial intelligence, cognitive science and many others. Basically,
	an agent has to choose a single or series of actions from a set of
	options, without knowing for sure their consequences. Schematically,
	two main approaches have been followed: either the agent learns which
	option is the correct one to choose in a given situation by trial
	and error, or the agent already has some knowledge on the possible
	consequences of his decisions; this knowledge being generally expressed
	as a conditional probability distribution. In the latter case, several
	optimal or suboptimal methods have been proposed to exploit this
	uncertain knowledge in various contexts. In this work, we propose
	following a different approach, based on the geometric intuition
	of distance. More precisely, we define a goal independent quasimetric
	structure on the state space, taking into account both cost function
	and transition probability. We then compare precision and computation
	time with classical approaches.}},
  affiliation = {Institut des Syst{\`e}mes Intelligents et Robotique - ISIR , Laboratoire
	de Physiologie de la Perception et de l'Action - LPPA , FLOWERS -
	INRIA Bordeaux - Sud-Ouest , Grenoble Images Parole Signal Automatique
	- GIPSA-lab},
  audience = {internationale },
  doi = {10.1371/journal.pone.0083411 },
  keywords = {optimal control; markov decision process; control under uncertainty},
  language = {Anglais},
  pdf = {http://hal.archives-ouvertes.fr/hal-00922767/PDF/article\_plos\_fig\_hal.pdf},
  url = {http://hal.archives-ouvertes.fr/hal-00922767}
}

@INPROCEEDINGS{Nguyen_ICDL:2011,
  author = {Nguyen, Sao Mai and Baranes, Adrien and Oudeyer, Pierre-Yves},
  title = {Bootstrapping Intrinsically Motivated Learning with Human Demonstrations},
  booktitle = {IEEE International Conference on Development and Learning},
  year = {2011},
  address = {Frankfurt, Germany},
  owner = {clement},
  timestamp = {2012.06.30}
}

@INPROCEEDINGS{Nguyen20122IISRHIC,
  author = {Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
  title = {Properties for Efficient Demonstrations to a Socially Guided Intrinsically
	Motivated Learner},
  booktitle = {21st IEEE International Symposium on Robot and Human Interactive
	Communication},
  year = {2012},
  abstract = {The combination of learning by intrinsic motivation and social learning
	has been shown to improve the learner's performance and gain precision
	over a wider range of motor skills, with for instance the SGIM-D
	learning algorithm. Nevertheless, this bootstrapping a-priori depends
	on the demonstrations made by the teacher. We propose in this paper
	to examine this dependence: to what extend the quality of the demonstrations
	can influence the learning performance, and which are the characteristics
	of a good demonstrator. Results on a fishing experiment highlights
	the importance of the difficulty of the demonstrated tasks, as well
	as the structure of the actions demonstrated.},
  owner = {clement},
  timestamp = {2012.10.23}
}

@ARTICLE{Nguyen2012PJBR,
  author = {Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
  title = {Active choice of teachers, learning strategies and goals for a socially
	guided intrinsic motivation learner},
  journal = {Paladyn Journal of Behavioural Robotics},
  year = {2012},
  volume = {3},
  pages = {136-146},
  number = {3},
  date-added = {2013-05-30 19:12:39 +0200},
  date-modified = {2013-05-30 19:12:39 +0200},
  doi = {10.2478/s13230-013-0110-z},
  issn = {2080-9778},
  keywords = {strategic learner; imitation learning; mimicry; emulation; artificial
	curiosity; intrinsic motivation; interactive learner; active learning;
	goal babbling; robot skill learning},
  language = {English},
  owner = {clement},
  publisher = {SP Versita},
  read = {1},
  timestamp = {2013.12.30},
  url = {http://dx.doi.org/10.2478/s13230-013-0110-z}
}

@INPROCEEDINGS{Ohala79,
  author = {Ohala, J.J.},
  title = {Moderator’s introduction to symposium on phonetic universals in phonological
	systems and their explanation},
  booktitle = {Proceedings of the 9th International Congress of Phonetic Sciences},
  year = {1979},
  volume = {3},
  pages = {181--185},
  owner = {clement},
  timestamp = {2011.05.04}
}

@INBOOK{Oller1980,
  chapter = {6},
  pages = {93--112},
  title = {{The emergence of the sounds of speech in infancy}},
  publisher = {Academic Press},
  year = {1980},
  editor = {Yeni-Komshian, Grace H. and Kavanagh, James F. and Ferguson, Charles
	A.},
  author = {Oller, D. K.},
  volume = {1},
  booktitle = {Child Phonology: Production},
  citeulike-article-id = {3152436},
  keywords = {infancy, infant-vocalization, infraphonology, phonological-development,
	som-project, vocal-development},
  location = {New York, London, Toronto, Sydney, San Francisco},
  owner = {clement},
  posted-at = {2008-08-24 21:51:06},
  priority = {0},
  timestamp = {2012.07.01}
}

@BOOK{Oller2000,
  title = {The Emergence of the Speech Capacity},
  publisher = {Mahwah, NJ: Lawrence Erlbaum Associates},
  year = {2000},
  author = {Oller, D. Kimbrough},
  __markedentry = {[clement:6]},
  abstract = {Oller constructs a new infrastructural model of vocal communication
	systems that permits provocative reconceptualizations of the ways
	infant vocalizations progress systematically toward speech, insightful
	comparaisons between..},
  isbn = {9780805826296},
  keywords = {Language Arts \& Disciplines / Speech},
  language = {en},
  owner = {clement},
  timestamp = {2012.10.30}
}

@BOOK{oudeyer2013sources,
  title = {Aux sources de la parole: Auto-organisation et {\'e}volution},
  publisher = {Editions Odile Jacob},
  year = {2013},
  author = {Oudeyer, P.Y.},
  series = {Sciences},
  isbn = {9782738175892},
  owner = {clement},
  timestamp = {2014.05.19}
}

@INBOOK{Oudeyer2011Developmentalconstraintson,
  chapter = {Developmental constraints on intrinsically motivated skill learning:
	towards addressing high-dimensions and unboundedness in the real
	world},
  title = {Intrinsically Motivated Cumulative Learning in Natural and Artificial
	Systems},
  publisher = {Springer},
  year = {to appear},
  editor = {Baldassarre, G. and Mirolli, M.},
  author = {Oudeyer, Pierre-Yves and Baranes, Adrien and Kaplan, Frederic and
	Ly, Olivier},
  owner = {clement},
  timestamp = {2012.06.30}
}

@CONFERENCE{Oudeyer2008ICER,
  author = {Oudeyer, Pierre-Yves and Kaplan, Frederic},
  title = {How can we define intrinsic motivation?},
  year = {2008},
  volume = {Modeling Cognitive Development in Robotic Systems},
  series = {8},
  journal = {International Conference on Epigenetic Robotics},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Oudeyer2007FN,
  author = {Oudeyer, Pierre-Yves and Kaplan, Frederic},
  title = {What is intrinsic motivation? a typology of computational approaches},
  journal = {Frontiers in Neurorobotics},
  year = {2007},
  volume = {1},
  owner = {clement},
  publisher = {Frontiers Research Foundation},
  timestamp = {2013.06.21}
}

@ARTICLE{Oudeyer2006CS,
  author = {Oudeyer, Pierre-Yves and Kaplan, Frederic},
  title = {Discovering communication},
  journal = {Connection Science},
  year = {2006},
  volume = {18},
  pages = {189--206},
  number = {2},
  month = {06},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Oudeyer2007ITEC,
  author = {Oudeyer, Pierre-Yves and Kaplan, Frederic and Hafner, V.},
  title = {Intrinsic Motivation Systems for Autonomous Mental Development},
  journal = {IEEE Transactions on Evolutionary Computation},
  year = {2007},
  volume = {11},
  pages = {265--286},
  number = {2},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Oudeyer2005,
  author = {{Pierre-Yves} Oudeyer},
  title = {The self-organization of speech sounds},
  journal = {Journal of Theoretical Biology},
  year = {2005},
  volume = {233},
  pages = {435--449},
  number = {3},
  month = apr,
  abstract = {The speech code is a vehicle of language: it defines a set of forms
	used by a community to carry information. Such a code is necessary
	to support the linguistic interactions that allow humans to communicate.
	How then may a speech code be formed prior to the existence of linguistic
	interactions? Moreover, the human speech code is discrete and compositional,
	shared by all the individuals of a community but different across
	communities, and phoneme inventories are characterized by statistical
	regularities. How can a speech code with these properties form? We
	try to approach these questions in the paper, using the "methodology
	of the artificial". We build a society of artificial agents, and
	detail a mechanism that shows the formation of a discrete speech
	code without pre-supposing the existence of linguistic capacities
	or of coordinated interactions. The mechanism is based on a low-level
	model of sensory-motor interactions. We show that the integration
	of certain very simple and non-language-specific neural devices leads
	to the formation of a speech code that has properties similar to
	the human speech code. This result relies on the self-organizing
	properties of a generic coupling between perception and production
	within agents, and on the interactions between agents. The artificial
	system helps us to develop better intuitions on how speech might
	have appeared, by showing how self-organization might have helped
	natural selection to find speech.},
  doi = {10.1016/j.jtbi.2004.10.025},
  issn = {0022-5193},
  keywords = {Agents, Artificial systems, Evolution, Forms, Origins of speech sounds,
	Phonetics, Phonology, Self-organization}
}

@ARTICLE{Oudeyer2004,
  author = {{Pierre-Yves} Oudeyer},
  title = {Aux sources du langage : l'auto-organisation de la parole},
  journal = {Cahiers Romans de Sciences Cognitives, In Cognito},
  year = {2004},
  volume = {2(2)},
  pages = {1--24},
  owner = {clement},
  timestamp = {2010.06.10}
}

@PHDTHESIS{Oudeyer_these,
  author = {{Pierre-Yves} Oudeyer},
  title = {L' auto-organisation de la parole},
  school = {Université Pierre et Marie Curie {(Paris)}},
  year = {2003},
  type = {Thèse doctorat},
  address = {{[S.l.]}},
  abstract = {Publication autorisée par le jury},
  keywords = {Agents, Auto-organisation, Exaptation, Parole, auto-organisation et
	évolution, Parole, origine et formes, Phonétique, Sytèmes artificiels},
  owner = {clement},
  timestamp = {2011.02.03}
}

@ARTICLE{Penfield1954,
  author = {Penfield, OM and CMG, MG and Jasper, MD},
  title = {{Epilepsy and the functional anatomy of the human brain.}},
  journal = {JAMA},
  year = {1954},
  volume = {155},
  pages = {86},
  number = {1},
  owner = {clement},
  publisher = {Am Med Assoc},
  timestamp = {2010.08.04}
}

@ARTICLE{Pickering:2012,
  author = {Pickering, M.J. and Garrod, S.},
  title = {An Integrated Theory of Language Production and Comprehension},
  journal = {Behavioral and Brain Sciences},
  year = {2012},
  volume = {to appear},
  owner = {clement},
  timestamp = {2012.10.23}
}

@INPROCEEDINGS{Pradalier03,
  author = {Cédric Pradalier and Francis Colas and Pierre Bessière},
  title = {Expressing Bayesian Fusion as a Product of Distributions: Applications
	in Robotics},
  booktitle = {Proceedings of the IEEE/RSJ International Conference on Intelligent
	Robots and Systems (IROS03)},
  year = {2003},
  volume = {2},
  pages = {1851--1856},
  owner = {clement},
  timestamp = {2011.05.06}
}

@ARTICLE{Pulvermuller2010,
  author = {Friedemann Pulvermüller and Luciano Fadiga},
  title = {Active perception: sensorimotor circuits as a cortical basis for
	language},
  journal = {Nature Reviews. Neuroscience},
  year = {2010},
  volume = {11},
  pages = {351--360},
  number = {5},
  month = may,
  note = {{PMID:} 20383203},
  abstract = {Action and perception are functionally linked in the brain, but a
	hotly debated question is whether perception and comprehension of
	stimuli depend on motor circuits. Brain language mechanisms are ideal
	for addressing this question. Neuroimaging investigations have found
	specific motor activations when subjects understand speech sounds,
	word meanings and sentence structures. Moreover, studies involving
	transcranial magnetic stimulation and patients with lesions affecting
	inferior frontal regions of the brain have shown contributions of
	motor circuits to the comprehension of phonemes, semantic categories
	and grammar. These data show that language comprehension benefits
	from frontocentral action systems, indicating that action and perception
	circuits are interdependent.},
  doi = {10.1038/nrn2811},
  issn = {1471-0048},
  keywords = {Animals, Brain, Humans, Language, Neural Pathways, Speech, Speech
	Perception},
  shorttitle = {Active perception}
}

@ARTICLE{Pulvermuller2006,
  author = {Friedemann Pulvermüller and Martina Huss and Ferath Kherif and Fermin
	Moscoso del Prado Martin and Olaf Hauk and Yury Shtyrov},
  title = {Motor cortex maps articulatory features of speech sounds},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2006},
  volume = {103},
  pages = {7865 --7870},
  number = {20},
  month = may,
  abstract = {The processing of spoken language has been attributed to areas in
	the superior temporal lobe, where speech stimuli elicit the greatest
	activation. However, neurobiological and psycholinguistic models
	have long postulated that knowledge about the articulatory features
	of individual phonemes has an important role in their perception
	and in speech comprehension. To probe the possible involvement of
	specific motor circuits in the speech-perception process, we used
	event-related functional {MRI} and presented experimental subjects
	with spoken syllables, including [p] and [t] sounds, which are produced
	by movements of the lips or tongue, respectively. Physically similar
	nonlinguistic signal-correlated noise patterns were used as control
	stimuli. In localizer experiments, subjects had to silently articulate
	the same syllables and, in a second task, move their lips or tongue.
	Speech perception most strongly activated superior temporal cortex.
	Crucially, however, distinct motor regions in the precentral gyrus
	sparked by articulatory movements of the lips and tongue were also
	differentially activated in a somatotopic manner when subjects listened
	to the lip- or tongue-related phonemes. This sound-related somatotopic
	activation in precentral gyrus shows that, during speech perception,
	specific motor circuits are recruited that reflect phonetic distinctive
	features of the speech sounds encountered, thus providing direct
	neuroimaging support for specific links between the phonological
	mechanisms for speech perception and production.},
  doi = {10.1073/pnas.0509989103}
}

@ARTICLE{Redford2001,
  author = {Melissa A. Redford and Chun Chi Chen and Risto Miikkulainen},
  title = {Constrained Emergence of Universals and Variation in Syllable Systems},
  journal = {Language and Speech},
  year = {2001},
  volume = {44},
  pages = {27-56},
  keywords = {Phonetics, Phonology},
  owner = {clement},
  timestamp = {2010.07.22}
}

@ARTICLE{rizzolatti_language_1998,
  author = {G Rizzolatti and M A Arbib},
  title = {Language within our grasp},
  journal = {Trends in Neurosciences},
  year = {1998},
  volume = {21},
  pages = {188--194},
  number = {5},
  month = may,
  note = {{PMID:} 9610880},
  abstract = {In monkeys, the rostral part of ventral premotor cortex (area F5)
	contains neurons that discharge, both when the monkey grasps or manipulates
	objects and when it observes the experimenter making similar actions.
	These neurons (mirror neurons) appear to represent a system that
	matches observed events to similar, internally generated actions,
	and in this way forms a link between the observer and the actor.
	Transcranial magnetic stimulation and positron emission tomography
	{(PET)} experiments suggest that a mirror system for gesture recognition
	also exists in humans and includes Broca's area. We propose here
	that such an observation/execution matching system provides a necessary
	bridge from'doing' to'communicating',as the link between actor and
	observer becomes a link between the sender and the receiver of each
	message.},
  issn = {0166-2236},
  keywords = {Animals, Brain, Communication, Frontal Lobe, Gestures, Hand Strength,
	Humans, Language, Pattern Recognition, Visual, Speech}
}

@ARTICLE{Rizzolatti1996,
  author = {G Rizzolatti and L Fadiga and V Gallese and L Fogassi},
  title = {Premotor cortex and the recognition of motor actions},
  journal = {Brain Research. Cognitive Brain Research},
  year = {1996},
  volume = {3},
  pages = {131--141},
  number = {2},
  month = mar,
  note = {{PMID:} 8713554},
  abstract = {In area F5 of the monkey premotor cortex there are neurons that discharge
	both when the monkey performs an action and when he observes a similar
	action made by another monkey or by the experimenter. We report here
	some of the properties of these 'mirror' neurons and we propose that
	their activity 'represents' the observed action. We posit, then,
	that this motor representation is at the basis of the understanding
	of motor events. Finally, on the basis of some recent data showing
	that, in man, the observation of motor actions activate the posterior
	part of inferior frontal gyrus, we suggest that the development of
	the lateral verbal communication system in man derives from a more
	ancient communication system based on recognition of hand and face
	gestures.},
  issn = {0926-6410},
  keywords = {Animals, Brain Mapping, Frontal Lobe, Macaca nemestrina, Motor Activity,
	Motor Cortex, Neurons, Pattern Recognition, Visual}
}

@ARTICLE{rochetcapellan_2008_JSLHR,
  author = {Rochet-Capellan, Am{\'e}lie and Laboissi{\`e}re, Rafael and Galvan,
	Arturo and Schwartz, Jean-Luc},
  title = {{The speech focus position effect on jaw-finger coordination in a
	pointing task}},
  journal = {Journal of Speech, Language, and Hearing Research},
  year = {2008},
  volume = {51},
  pages = {1507-1521},
  number = {6},
  abstract = {{Purpose: This paper investigates jaw-finger coordination in a task
	involving pointing to a target while naming it with a 'CVCV (e.g.
	/'papa/) vs. CV'CV (e.g. /pa'pa/) word. According to our working
	hypothesis, the pointing apex (gesture extremum) would be synchronized
	with the apex of the jaw opening gesture corresponding to the stressed
	syllable. Method:Jaw and finger motions were recorded using Optotrak.
	The effects of stress position on jaw-finger coordination were tested
	across different target positions (near vs. far) and different consonants
	in the target word (/t/ vs. /p/). Twenty native Portuguese Brazilian
	speakers participated in the experiment (all conditions). Results:
	Jaw response starts earlier and finger-target alignment period is
	longer for CV'CV words than for 'CVCV ones. The apex of the jaw opening
	gesture for the stressed syllable appears synchronized to the onset
	of the finger-target alignment period (corresponding to the pointing
	apex) for 'CVCV words, and with the offset of that period for CV'CV
	ones. Conclusions:For both stress conditions, the stressed syllable
	occurs within the finger-target alignment period due to tight finger-jaw
	coordination. This result is interpreted as an evidence for an anchoring
	of the speech deictic site (part of speech that shows) in the pointing
	gesture.}},
  affiliation = {Grenoble Images Parole Signal Automatique - GIPSA-lab , Max Planck
	Institute for Human Cognitive and Brain Sciences Department of Psychology
	- MAX PLANCK INSTITUTE},
  audience = {internationale },
  doi = {10.1044/1092-4388(2008/07-0173 },
  hal_id = {hal-00282323},
  language = {Anglais},
  owner = {clement},
  pdf = {http://hal.archives-ouvertes.fr/hal-00282323/PDF/Rochet\_JSLHR.pdf},
  timestamp = {2013.12.31},
  url = {http://hal.archives-ouvertes.fr/hal-00282323}
}

@ARTICLE{rochetcapellan_ostry_2011,
  author = {Rochet-Capellan, Am{\'e}lie and Ostry, David J},
  title = {{Simultaneous acquisition of multiple auditory-motor transformations
	in speech}},
  journal = {Journal of Neuroscience},
  year = {2011},
  volume = {31},
  pages = {2657-62},
  number = {7 },
  month = Feb,
  abstract = {{The brain easily generates the movement that is needed in a given
	situation. Yet surprisingly, the results of experimental studies
	suggest that it is difficult to acquire more than one skill at a
	time. To do so, it has generally been necessary to link the required
	movement to arbitrary cues. In the present study, we show that speech
	motor learning provides an informative model for the acquisition
	of multiple sensorimotor skills. During training, subjects were required
	to repeat aloud individual words in random order while auditory feedback
	was altered in real-time in different ways for the different words.
	We found that subjects can quite readily and simultaneously modify
	their speech movements to correct for these different auditory transformations.
	This multiple learning occurs effortlessly without explicit cues
	and without any apparent awareness of the perturbation. The ability
	to simultaneously learn several different auditory-motor transformations
	is consistent with the idea that, in speech motor learning, the brain
	acquires instance-specific memories. The results support the hypothesis
	that speech motor learning is fundamentally local.}},
  affiliation = {Grenoble Images Parole Signal Automatique - GIPSA-lab , McGill University},
  audience = {internationale },
  doi = {10.1523/JNEUROSCI.6020-10.2011 },
  hal_id = {hal-00743779},
  language = {Anglais},
  owner = {clement},
  timestamp = {2013.12.31},
  url = {http://hal.archives-ouvertes.fr/hal-00743779}
}

@ARTICLE{rochetcapellan_2007_JASA,
  author = {Rochet-Capellan, Am{\'e}lie and Schwartz, Jean-Luc},
  title = {{An articulatory basis for the Labial-to-Coronal effect: /pata/ seems
	a more stable articulatory pattern than /tapa/}},
  journal = {Journal of the Acoustical Society of America},
  year = {2007},
  volume = {121},
  pages = {3740-3754},
  number = {6 },
  month = Jun,
  abstract = {{This paper investigates the coordination between the jaw, the tongue
	tip and the lower lip during repetition with rate increase of Labial-to-Coronal
	(LaCo) Consonant-Vowel-Consonant-Vowel disyllables (e.g./pata/) and
	Coronal-to-Labial (CoLa) ones (e.g. /tapa/) by French speakers. For
	the two types of disyllables: (1) the speeding process induces a
	shift from two jaw cycles per disyllable to a single cycle; (2) this
	shift modifies the coordination between the jaw and the constrictors
	and (3) comes with a progression towards either a LaCo attractor
	(e.g. (/pata/ or /tapa/)->/pat{\'a}/->/pt{\'a}/) or a CoLa one (e.g.
	(/pata/ or /tapa/->/tap{\'a}/->/tp{\'a}/). Yet, (4) the LaCo attractor
	is clearly favored regardless of the initial sequencing. These results
	are interpreted as evidence that a LaCo CVCV disyllable could be
	a more stable coordinative pattern for the lip-tongue-jaw motor system
	than a CoLa one. They are discussed in relation with the so-called
	LC effect that is the preference for LaCo associations rather than
	CoLa ones in CV.CV disyllables in both world languages and infants'
	first words.}},
  affiliation = {Grenoble Images Parole Signal Automatique - GIPSA-lab},
  audience = {internationale },
  hal_id = {hal-00157938},
  language = {Anglais},
  owner = {clement},
  pdf = {http://hal.archives-ouvertes.fr/hal-00157938/PDF/jasa\_final.pdf},
  timestamp = {2013.12.31},
  url = {http://hal.archives-ouvertes.fr/hal-00157938}
}

@INPROCEEDINGS{Rochet_Capellan_2007,
  author = {{A}m{\'e}lie {Rochet-Capellan} and {J}ean-{L}uc {S}chwartz and {R}afael
	{L}aboissi{\`e}re and {A}rturo {G}alvan},
  title = { {T}wo {CV} syllables for one pointing gesture as an optimal ratio
	for jaw-arm coordination in a deictic task: {A} preliminary study},
  booktitle = {{P}roceedings of the 2nd {E}uropean {C}ognitive {S}cience {C}onference,
	{E}uro{C}og{S}ci07 2nd {E}uropean {C}ognitive {S}cience {C}onference,
	{E}uro{C}og{S}ci07 },
  year = {2007},
  series = {23-27 {M}ay 2007, {D}elphi, {G}reece },
  pages = {608-613 },
  address = {{D}elphi {G}reece },
  month = {05},
  publisher = {{S}. {V}osniadou, {D}. {K}ayser, \& {A}. {P}rotopapas },
  day = {23},
  owner = {clement},
  timestamp = {2010.10.28}
}

@ARTICLE{Rolf2010_TAMD,
  author = {Rolf, M. and Steil, J. and Gienger, M.},
  title = {Goal Babbling permits Direct Learning of Inverse Kinematics},
  journal = {IEEE Trans. Autonomous Mental Development},
  year = {2010},
  volume = {2},
  pages = {216-229},
  number = {3},
  date-added = {2012-03-26 23:10:15 +0200},
  date-modified = {2012-03-26 23:10:22 +0200},
  owner = {clement},
  timestamp = {2012.06.30}
}

@INBOOK{Romand2000,
  chapter = {Introduction au fonctionnement du système auditif},
  pages = {101--133},
  title = {La parole},
  publisher = {Hermès},
  year = {2000},
  editor = {Escudier, P. and Schwartz, J-L.},
  author = {Romand, R.},
  owner = {clement},
  timestamp = {2010.08.04}
}

@PHDTHESIS{Rousset2004,
  author = {Rousset, I.},
  title = {Structures Syllabiques et Lexicales des Langues du Monde : Typologies,
	Tendances Universelles et Contraintes Substancielle},
  school = {Université Stendhal, Grenoble},
  year = {2004},
  owner = {clement},
  timestamp = {2011.05.06}
}

@ARTICLE{Roy2005,
  author = {Alice C. Roy and Michael A. Arbib},
  title = {The syntactic motor system},
  journal = {Gesture},
  year = {2005},
  volume = {5},
  pages = {7--37},
  number = {1},
  doi = {10.1075/gest.5.1.03roy},
  issn = {15681475}
}

@BOOK{Ruhlen1996,
  title = {The Origin of Language: Tracing the Evolution of the Mother Tongue},
  publisher = {New York: John Wiley \& Sons},
  year = {1996},
  author = {Merritt Ruhlen},
  month = aug,
  isbn = {0471159638},
  owner = {clement},
  shorttitle = {The Origin of Language},
  timestamp = {2011.05.05}
}

@ARTICLE{ryan2000intrinsic,
  author = {Ryan, Richard M and Deci, Edward L},
  title = {Intrinsic and extrinsic motivations: Classic definitions and new
	directions},
  journal = {Contemporary educational psychology},
  year = {2000},
  volume = {25},
  pages = {54--67},
  number = {1},
  owner = {clement},
  publisher = {Elsevier},
  timestamp = {2013.05.22}
}

@INPROCEEDINGS{Sasamoto_icdl2013_vocal_robot,
  author = {Sasamoto, Y. and Nishijima, N. and Minoru, A.},
  title = {Towards understanding the origin of infant directed speech: A vocal
	robot with infant-like articulation},
  booktitle = {Development and Learning and Epigenetic Robotics (ICDL), 2013 IEEE
	Third Joint International Conference on},
  year = {2013},
  pages = {1-2},
  abstract = {Infant-Directed Speech (IDS) is the non-standard form of caregivers'
	speech to their infants. Developmental studies indicate that IDS
	changes from infant-directed to adult-directed depending on infant's
	age and/or linguistic level. However, it is still unclear what features
	in infants cause IDS. This article introduces a vocal robot with
	an infant-like articulatory system to attack the issue by means of
	a constructive approach. A preliminary experiment implies that our
	robot can vocalize structurally similar to infant articulation although
	it is mechanically rather different.},
  doi = {10.1109/DevLrn.2013.6652562},
  keywords = {linguistics;psychology;speech;IDS;caregiver speech;developmental studies;infant
	articulation;infant directed speech;infant-directed speech;infant-like
	articulation;infant-like articulatory system;linguistic level;vocal
	robot;Acoustics;Actuators;Conferences;Pediatrics;Robots;Speech;Tongue},
  owner = {clement},
  timestamp = {2014.01.06}
}

@ARTICLE{savariaux_compensation_1999,
  author = {C Savariaux and P Perrier and J P Orliaguet and J L Schwartz},
  title = {Compensation strategies for the perturbation of French [u] using
	a lip tube. {II.} Perceptual analysis},
  journal = {The Journal of the Acoustical Society of America},
  year = {1999},
  volume = {106},
  pages = {381--393},
  number = {1},
  month = jul,
  note = {{PMID:} 10420629},
  abstract = {A perceptual analysis of the French vowel [u] produced by 10 speakers
	under normal and perturbed conditions {(Savariaux} et al., 1995)
	is presented which aims at characterizing in the perceptual domain
	the task of a speaker for this vowel, and, then, at understanding
	the strategies developed by the speakers to deal with the lip perturbation.
	Identification and rating tests showed that the French [u] is perceptually
	fairly well described in the {[F1,} {(F2-F0)]} plane, and that the
	parameter {(((F2-F0)} + F1)/2) (all frequencies in bark) provides
	a good overall correlate of the "grave" feature classically used
	to describe the vowel [u] in all languages. This permitted reanalysis
	of the behavior of the speakers during the perturbation experiment.
	Three of them succeed in producing a good [u] in spite of the lip
	tube, thanks to a combination of limited changes on F1 and {(F2-F0),}
	but without producing the strong backward movement of the tongue,
	which would be necessary to keep the {[F1,F2]} pattern close to the
	one measured in normal speech. The only speaker who strongly moved
	his tongue back and maintained F1 and F2 at low values did not produce
	a perceptually well-rated [u], but additional tests demonstrate that
	this gesture allowed him to preserve the most important phonetic
	features of the French [u], which is primarily a back and rounded
	vowel. It is concluded that speech production is clearly guided by
	perceptual requirements, and that the speakers have a good representation
	of them, even if they are not all able to meet them in perturbed
	conditions.},
  issn = {0001-4966},
  keywords = {Adult, Female, France, Humans, Linguistics, Lip, Male, Middle Aged,
	Perceptual Masking, Phonetics, Speech Acoustics, Speech Perception,
	Speech Production Measurement}
}

@CONFERENCE{Schmidhuber91c,
  author = {Schmidhuber, J.},
  title = {A possibility for implementing curiosity and boredom in model-building
	neural controllers},
  booktitle = {Proc. SAB'91},
  year = {1991},
  editor = {J. A. Meyer and S. W. Wilson},
  pages = {222-227},
  date-added = {2012-04-02 02:25:06 +0000},
  date-modified = {2012-04-02 02:25:43 +0000},
  owner = {clement},
  timestamp = {2012.10.23}
}

@ARTICLE{Schmidhuber2010ITAMD,
  author = {Schmidhuber, J.},
  title = {Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010)},
  journal = {IEEE Transactions on Autonomous Mental Development},
  year = {2010},
  volume = {2},
  pages = {230-247},
  number = {3},
  bdsk-file-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfoAAAAAAfoAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMgG0jtIKwAAAAhh0BhTY2htaWRodWJlcjIwMTBJVEFNRC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAceixyebmPAAAAAAAAAAAAAEABAAACSAAAAAAAAAAAAAAAAAAAAADcGRmAAAQAAgAAMgGthsAAAARAAgAAMnmyhwAAAABABwACGHQAGommAAIXGQACFxhAAhPqQAISroAAJI/AAIAYk1hY2ludG9zaCBIRDpVc2VyczptYWk6RG9jdW1lbnRzOlJlY2hlcmNoZTpCaWJpb2dyYXBoaWU6T3RoZXJzV3JpdGluZzpwZGY6U2NobWlkaHViZXIyMDEwSVRBTUQucGRmAA4AMgAYAFMAYwBoAG0AaQBkAGgAdQBiAGUAcgAyADAAMQAwAEkAVABBAE0ARAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAVVVzZXJzL21haS9Eb2N1bWVudHMvUmVjaGVyY2hlL0JpYmlvZ3JhcGhpZS9PdGhlcnNXcml0aW5nL3BkZi9TY2htaWRodWJlcjIwMTBJVEFNRC5wZGYAABMAAS8AABUAAgAK//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECpPdGhlcnNXcml0aW5nL3BkZi9TY2htaWRodWJlcjIwMTBJVEFNRC5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACngKgAqUCrgK5Ar0CywLSAtsDCAMNAxADHQMiAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAzQ=},
  date-added = {2011-05-04 11:21:09 +0200},
  date-modified = {2011-05-04 11:23:15 +0200},
  owner = {clement},
  timestamp = {2012.06.30}
}

@INBOOK{Schroeder1979,
  chapter = {Objective measure of certain speech signal degradations based on
	masking properties of human auditory perception},
  pages = {217--229},
  title = {Frontiers of Speech Communication Research},
  publisher = {London Academic Press},
  year = {1979},
  editor = {B. Lindblom andS. Ohman},
  author = {Schroeder, M.R. and Atal, B.S. and Hall, J.L},
  owner = {clement},
  timestamp = {2011.04.14}
}

@ARTICLE{Schroeder1979a,
  author = {R. Schroeder and B. S. Atal and J. L. Hall},
  title = {Optimizing digital speech coders by exploiting masking properties
	of the human ear},
  journal = {Journal of the Acoustical Society of America},
  year = {1979},
  volume = {66},
  pages = {1647--1652},
  number = {6},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Schwartz_PACT_2002,
  author = {J. L. Schwartz and C. Abry and L. J Bo{\textbackslash}ë and M. Cathiard},
  title = {Phonology in a theory of perception-for-action-control},
  journal = {Phonetics, phonology and cognition},
  year = {2002},
  pages = {244–280},
  owner = {clement},
  timestamp = {2010.05.18}
}

@ARTICLE{Schwartz2012a,
  author = {Jean-Luc Schwartz and Anahita Basirat and Lucie M\'{e}nard and Marc
	Sato},
  title = {The {P}erception-for-{A}ction-{C}ontrol {T}heory ({PACT}): A perceptuo-motor
	theory of speech perception},
  journal = {Journal of Neurolinguistics},
  year = {2012},
  volume = {25},
  pages = {336--354},
  number = {5},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Schwartz1997c,
  author = {Schwartz, J.-L. and Bo\"{e}, L.-J. and Vall\'{e}e, N. and C. Abry
	},
  title = {Major Trends in Vowel System Inventories},
  journal = {Journal of Phonetics},
  year = {1997},
  volume = {25},
  pages = {233--253},
  number = {3},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Schwartz_GroundingPlosives_2012,
  author = {Schwartz,Jean-luc and Bo{\"e},Louis-jean and Badin,Pierre and Sawallis,Thomas},
  title = {Grounding stop place systems in the perceptuo-motor substance of
	speech: On the universality of the labial-coronal-velar stop series},
  journal = {Journal of Phonetics},
  year = {2012},
  volume = {40},
  pages = {20--36},
  owner = {clement},
  timestamp = {2012.07.11}
}

@ARTICLE{Schwartz_PACT_2010,
  author = {{Jean-Luc} Schwartz and Anahita Basirat and Lucie Ménard and Marc
	Sato},
  title = {The {Perception-for-Action-Control} Theory {(PACT):} A perceptuo-motor
	theory of speech perception},
  journal = {Journal of Neurolinguistics},
  year = {2010},
  volume = {In Press},
  abstract = {It is an old-standing debate in the field of speech communication
	to determine whether speech perception involves auditory or multisensory
	representations and processing, independently on any procedural knowledge
	about the production of speech units or on the contrary if it is
	based on a recoding of the sensory input in terms of articulatory
	gestures, as posited in the Motor Theory of Speech Perception. The
	discovery of mirror neurons in the last 15 years has strongly renewed
	the interest for motor theories. However, while these neurophysiological
	data clearly reinforce the plausibility of the role of motor properties
	in perception, it could lead in our view to incorrectly de-emphasise
	the role of perceptual shaping, crucial in speech communication.
	The so-called {Perception-for-Action-Control} Theory {(PACT)} aims
	at defining a theoretical framework connecting in a principled way
	perceptual shaping and motor procedural knowledge in speech multisensory
	processing in the human brain. In this paper, the theory is presented
	in details. It is described how this theory fits with behavioural
	and linguistic data, concerning firstly vowel systems in human languages,
	and secondly the perceptual organization of the speech scene. Finally
	a neuro-computational framework is presented in connection with recent
	data on the possible functional role of the motor system in speech
	perception.},
  doi = {10.1016/j.jneuroling.2009.12.004},
  issn = {0911-6044},
  keywords = {Dorsal route, Multisensory interactions, Neurocomputational model,
	Perceptual organisation, Perceptuo-motor interaction, Speech Perception,
	Vowel perception},
  shorttitle = {The {Perception-for-Action-Control} Theory {(PACT)}}
}

@ARTICLE{Schwartz1997a,
  author = {{Jean-Luc} Schwartz and {Louis-Jean} Bo\"{e} and Nathalie Vall\'{e}e
	and Christian Abry},
  title = {Major trends in vowel system inventories},
  journal = {Journal of Phonetics},
  year = {1997},
  volume = {25},
  pages = {233--253},
  number = {3},
  month = jul,
  abstract = {{{\textless}p{\textgreater}{\textless}br/{\textgreater}The} search
	for universal tendencies in the languages of the world is a necessary
	anchor point for any theoretical approach to phonetics. The present
	typology of vowel systems aims to provide material for testing substance-based
	theories, including, among others, the {Dispersion-Focalization}
	Theory of vowel systems presented in a companion paper {(Schwartz,}
	Bo\"{e}, Vall\'{e}e \& Abry, this issue). It is focused on theeconomyof
	vowel systems, specifically the way a system of vowels functions
	as a whole, and the way vowels interact within a given system. The
	{UPSID} {(UCLA} Phonological Segment Inventory {Database,Maddieson,}
	1984) inventory is analyzed using an original methodology, with the
	following main results.{\textless}br/{\textgreater}1.~Vowel systems
	first exploit a "primary" system of sounds; with more than 9 vowels,
	there is a clear trend for exploiting at least one new dimension
	("secondary " systems).{\textless}br/{\textgreater}2.~Primary systems
	mainly contain 3 to 9 vowels, and secondary systems 1 to 7 vowels,
	both with a preference for 5 vowels.{\textless}br/{\textgreater}3.~In
	both primary and secondary systems, vowels are mainly concentrated
	at the periphery. For peripheral systems, symmetry (same number of
	front and back vowels) is the rule; if there is an asymmetry, the
	number of front vowels is generally greater than the number of back
	vowels.{\textless}br/{\textgreater}4.~For "interior" vowels in primary
	systems, central vowels are preferred; among non-central vowels,
	front rounded vowels are twice as frequent as back unrounded ones.{\textless}br/{\textgreater}5.~Schwa
	is the preferred interior vowel, and it does not seem to interact
	with other sounds within vowel systems.{\textless}/p{\textgreater}},
  doi = {10.1006/jpho.1997.0044},
  issn = {0095-4470},
  owner = {clement},
  timestamp = {2011.04.01}
}

@ARTICLE{Schwartz1997,
  author = {{Jean-Luc} Schwartz and {Louis-Jean} Bo{\"e} and Nathalie Vallée
	and Christian Abry},
  title = {The {Dispersion-Focalization} Theory of vowel systems},
  journal = {Journal of Phonetics},
  year = {1997},
  volume = {25},
  pages = {255--286},
  number = {3},
  abstract = {The {Dispersion-Focalization} Theory {(DFT)} attempts to predict vowel
	systems based on the minimization of an energy function summing two
	perceptual components: global dispersion, which is based on inter-vowel
	distances; and local focalization, which is based on intra-vowel
	spectral salience related to the proximity of formants. The computation
	takes place in an auditory (formant-based) space, and is controlled
	by two parameters,[lambda],which sets the respective weight of F1and
	higher formants in auditory distances, and[alpha],which sets the
	respective weights of the dispersion and focalization components.
	In this study, we first sample the acoustic space with 33 "prototypes"
	associated with the major primary articulations for vowels. Then,
	for a given number of vowels, we define two different tools, "phase
	spaces" for dealing with optimal systems and "stability " for characterizing
	sub-optimal ones. The corresponding predictions are compared with
	the main trends of vowel systems analyzed in a companion paper {(Schwartz,}
	Bo{\"e}, Vallée \& Abry, this issue). We then derive a region in
	the ([lambda], [alpha])space for which theory predictions fit quite
	well with phonological inventories, with a special concern for two
	problems, namely peripheral vowels and front rounded vowels. Finally
	we stress the difficulty of predicting some trends of vowel systems
	linked to the organization of vowels in series, which could constitute
	a limit to substance-based predictions of vowel inventories.},
  doi = {10.1006/jpho.1997.0043},
  issn = {0095-4470}
}

@INPROCEEDINGS{schwartz_speech_2007,
  author = {{Jean-Luc} Schwartz and Amélie {Rochet-Capellan} and Clément {Moulin-Frier}},
  title = {Speech at reach of hand and mouth: Theoretical arguments, experimental
	facts and computational advances},
  booktitle = {Workshop ``Vocoid – Vocalization, {COmmmunication,} Imitation and
	Deixis in adult and infant human and non human primates''},
  year = {2007}
}

@ARTICLE{Scott2003,
  author = {Sophie K Scott and Ingrid S Johnsrude},
  title = {The neuroanatomical and functional organization of speech perception},
  journal = {Trends in Neurosciences},
  year = {2003},
  volume = {26},
  pages = {100--107},
  number = {2},
  month = feb,
  note = {{PMID:} 12536133},
  abstract = {A striking property of speech perception is its resilience in the
	face of acoustic variability (among speech sounds produced by different
	speakers at different times, for example). The robustness of speech
	perception might, in part, result from multiple, complementary representations
	of the input, which operate in both acoustic-phonetic feature-based
	and articulatory-gestural domains. Recent studies of the anatomical
	and functional organization of the non-human primate auditory cortical
	system point to multiple, parallel, hierarchically organized processing
	pathways that involve the temporal, parietal and frontal cortices.
	Functional neuroimaging evidence indicates that a similar organization
	might underlie speech perception in humans. These parallel, hierarchical
	processing 'streams', both within and across hemispheres, might operate
	on distinguishable, complementary types of representations and subserve
	complementary types of processing. Two long-opposing views of speech
	perception have posited a basis either in acoustic feature processing
	or in gestural motor processing; the view put forward here might
	help reconcile these positions.},
  issn = {0166-2236},
  keywords = {Acoustic Stimulation, Animals, Auditory Cortex, Auditory Pathways,
	Cerebral Cortex, Evoked Potentials, Auditory, Haplorhini, Humans,
	Nerve Net, Speech Perception}
}

@BOOK{Seeley2006,
  title = {Essentials of Anatomy \& Physiology},
  publisher = {{McGraw-Hill} {Science/Engineering/Math}},
  year = {2006},
  author = {Rod R. Seeley and Trent D. Stephens and Philip Tate},
  edition = {6},
  month = mar,
  isbn = {0073228052},
  owner = {clement},
  timestamp = {2011.05.05}
}

@PHDTHESIS{Serkhane_These,
  author = {J.E. Serkhane},
  title = {Un bébé androïde vocalisant: Etude et modélisation des mécanismes
	d'exploration vocale et d'imitation orofaciale dans le developpement
	de la parole},
  school = {Institut Polytechnique de Grenoble},
  year = {2005},
  owner = {clement},
  timestamp = {2010.08.04}
}

@ARTICLE{Serkhane2005,
  author = {Serkhane, Jihene and Schwartz, Jean-Luc and Bessiere, Pierre},
  title = {Building a talking baby robot: A contribution to the study of speech
	acquisition and evolution},
  journal = {Interaction Studies},
  year = {2005},
  volume = {6},
  pages = {253--286},
  number = {2},
  issn = {1572-0373},
  owner = {clement},
  publisher = {John Benjamins Publishing Company}
}

@ARTICLE{Serkhane2007,
  author = {Serkhane, J.E. and Schwartz, J.-L. and Bo\"{e}, L.-J. and Davis,
	B.L. and Matyear, C.L. },
  title = {Infants' vocalizations analyzed with an articulatory model: A preliminary
	report},
  journal = {Journal of Phonetics},
  year = {2007},
  volume = {35},
  pages = {321--340},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INBOOK{Sigismund_1856,
  chapter = {Kind und Welt},
  pages = {17--18},
  title = {Child language: a book of readings},
  publisher = {Englewood Cliffs, NJ: Prentice-Hall. (Original work published in
	1856)},
  year = {1971},
  editor = {Bar-Adon, Aaron and Leopold, Werner F},
  author = {Sigismund, B.},
  owner = {clement},
  timestamp = {2013.06.25}
}

@ARTICLE{Skipper2007,
  author = {Jeremy I. Skipper and Virginie van Wassenhove and Howard C. Nusbaum
	and Steven L. Small},
  title = {Hearing Lips and Seeing Voices: How Cortical Areas Supporting Speech
	Production Mediate Audiovisual Speech Perception},
  journal = {Cerebral Cortex},
  year = {2007},
  pages = {bhl147},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{srivastava2013first,
  author = {Srivastava, Rupesh Kumar and Steunebrink, Bas R and Schmidhuber,
	J{\"u}rgen},
  title = {First experiments with PowerPlay},
  journal = {Neural Networks},
  year = {2013},
  volume = {41},
  pages = {130--136},
  owner = {clement},
  publisher = {Elsevier},
  timestamp = {2013.06.28}
}

@INPROCEEDINGS{Steels96,
  author = {L. Steels},
  title = {Emergent Adaptive Lexicons},
  booktitle = {SAB96},
  year = {1996},
  editor = {Maes, P. and Mataric, M. and Meyer, J.-A. and Pollack, J. and Wilson,
	S. W.},
  address = {Cambridge, MA},
  publisher = {MIT Press},
  keywords = {self-organization, lexicons, agents,evolutionary linguistics, simulation},
  owner = {clement},
  timestamp = {2010.06.07}
}

@INCOLLECTION{Steels1999,
  author = {Steels, L.},
  title = {The Spontaneous Self-organization of an Adaptive Language},
  booktitle = {Machine Intelligence 15},
  publisher = {Oxford University Press},
  year = {1999},
  editor = {Muggleton, S.},
  pages = {205--224},
  address = {Oxford},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INPROCEEDINGS{Steels2006,
  author = {Luc Steels},
  title = {How to do experiments in artificial language evolution and why},
  booktitle = {Proceedings of the 6th International Conference on the Evolution
	of Language},
  year = {2006},
  pages = {323--332}
}

@ARTICLE{Steels97,
  author = {L. Steels},
  title = {The synthetic modeling of language origins},
  journal = {Evolution of Communication},
  year = {1997},
  volume = {1},
  pages = {1--34},
  number = {1},
  keywords = {agents, evolutionary linguistics, language games, simulation}
}

@ARTICLE{Steels1994,
  author = {Steels, L.},
  title = {The Artificial Life Roots of Artificial Intelligence},
  journal = {Artificial Life Journal},
  year = {1994},
  volume = {1},
  pages = {89--125},
  number = {1},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@ARTICLE{Stevens1989,
  author = {Stevens, K.N.},
  title = {{On the quantal nature of speech}},
  journal = {Journal of phonetics},
  year = {1989},
  volume = {17},
  pages = {3--45},
  number = {1},
  owner = {clement},
  timestamp = {2010.07.22}
}

@ARTICLE{Stevens2010,
  author = {Stevens, K.N. and Keyser, S.J.},
  title = {Quantal theory, enhancement and overlap},
  journal = {Journal of Phonetics},
  year = {2010},
  volume = {38},
  pages = {10--19},
  number = {1},
  __markedentry = {[clement:]},
  owner = {clement},
  publisher = {Elsevier},
  timestamp = {2012.09.19}
}

@INCOLLECTION{Stevens1972,
  author = {{KN} Stevens},
  title = {The quantal nature of speech: Evidence from articulatory-acoustic
	data},
  booktitle = {Human communication: A unified view},
  publisher = {{McGraw-Hill}},
  year = {1972},
  editor = {{EE} David and {PB} Denes},
  pages = {51--66},
  keywords = {lsb},
  owner = {clement},
  shorttitle = {The quantal nature of speech},
  timestamp = {2011.05.05}
}

@INCOLLECTION{studdert-kennedy03,
  author = {M. Studdert-Kennedy and L. Goldstein},
  title = {Launching language: The gestural origin of discrete infinity},
  booktitle = {Language Evolution: The States of the Art},
  publisher = {Oxford University Press},
  year = {2003},
  editor = {M.H. Christiansen and S. Kirby},
  owner = {clement},
  timestamp = {2011.04.11}
}

@INPROCEEDINGS{stulp12emergent,
  author = {Freek Stulp and Pierre-Yves Oudeyer},
  title = {Emergent Proximo-Distal Maturation through Adaptive Exploration},
  booktitle = {International Conference on Development and Learning (ICDL)},
  year = {2012},
  abstract = {Life-long robot learning in the high-dimensional real world requires
	guided and structured exploration mechanisms. In this developmental
	context, we investigate here the use of the recently proposed PI2-CMAES
	episodic reinforcement learning algorithm, which is able to learn
	high-dimensional motor tasks through adaptive control of exploration.
	By studying PI2-CMAES in a reaching task on a simulated arm, we observe
	two developmental properties. First, we show how PI2-CMAES autonomously
	and continuously tunes the global exploration/exploitation trade-off,
	allowing it to re-adapt to changing tasks. Second, we show how PI2-CMAES
	spontaneously self-organizes a maturational structure whilst exploring
	the degrees-of-freedom (DOFs) of the motor space. In particular,
	it automatically demonstrates the so-called \emph{proximo-distal
	maturation} observed in humans: after first freezing distal DOFs
	while exploring predominantly the most proximal DOF, it progressively
	frees exploration in DOFs along the proximo-distal body axis. These
	emergent properties suggest the use of PI2-CMAES as a general tool
	for studying reinforcement learning of skills in life-long developmental
	learning contexts.},
  bib2html_pubtype = {Refereed Conference Paper,Awards},
  bib2html_rescat = {Reinforcement Learning of Robot Skills},
  owner = {clement},
  timestamp = {2013.12.30}
}

@ARTICLE{stulp13adaptive,
  author = {Freek Stulp and Pierre-Yves Oudeyer},
  title = {Adaptive Exploration through Covariance Matrix Adaptation Enables
	Developmental Motor Learning},
  journal = {Paladyn. Journal of Behavioral Robotics},
  year = {2012},
  volume = {3},
  pages = {128--135},
  number = {3},
  month = {September},
  bib2html_pubtype = {Journal},
  bib2html_rescat = {Reinforcement Learning of Robot Skills}
}

@ARTICLE{Sussman1999,
  author = {Harvey M. Sussman and Celeste Duder and Eileen Dalston and Antonina
	Cacciatore},
  title = {An Acoustic Analysis of the Development of {CV} Coarticulation: A
	Case Study},
  journal = {J Speech Lang Hear Res},
  year = {1999},
  volume = {42},
  pages = {1080--1096},
  number = {5},
  month = oct,
  abstract = {This study analyzed stop consonant-vowel productions from babbling
	to meaningful speech in a single female child spanning the period
	from age 7 months to age 40 months. A total of 7,888 utterances (3,103
	{[bV],} 3,236 {[dV],} and 1,549 {[gV])} were analyzed to obtain frequencies
	at F2 onset and F2 at vocalic center for each utterance. A linear
	regression line ("locus equation") was fit to the cluster of F2 coordinates
	per stop place category produced during each month. The slope of
	the regression lines provided a numerical index of vowel-induced
	coarticulation on consonant productions. Labial, alveolar, and velar
	{CV} productions followed distinct articulatory paths toward adult-like
	norms of coarticulation. Inferences about the gradual emergence of
	segmental independence of the consonant and vowel in the three stop
	place environments were made from locus equation scatterplots and
	mean F2 onset and F2 midvowel frequencies obtained across babbling,
	early words, and natural speech.},
  doi = {<p></p>},
  owner = {clement},
  shorttitle = {An Acoustic Analysis of the Development of {CV} Coarticulation},
  timestamp = {2011.05.01}
}

@ARTICLE{Sussman1998,
  author = {H M Sussman and D Fruchter and J Hilbert and J Sirosh},
  title = {Linear correlates in the speech signal: the orderly output constraint},
  journal = {The Behavioral and Brain Sciences},
  year = {1998},
  volume = {21},
  pages = {241--259; discussion 260-299},
  number = {2},
  month = apr,
  note = {{PMID:} 10097014},
  abstract = {Neuroethological investigations of mammalian and avian auditory systems
	have documented species-specific specializations for processing complex
	acoustic signals that could, if viewed in abstract terms, have an
	intriguing and striking relevance for human speech sound categorization
	and representation. Each species forms biologically relevant categories
	based on combinatorial analysis of information-bearing parameters
	within the complex input signal. This target article uses known neural
	models from the mustached bat and barn owl to develop, by analogy,
	a conceptualization of human processing of consonant plus vowel sequences
	that offers a partial solution to the noninvariance dilemma--the
	nontransparent relationship between the acoustic waveform and the
	phonetic segment. Critical input sound parameters used to establish
	species-specific categories in the mustached bat and barn owl exhibit
	high correlation and linearity due to physical laws. A cue long known
	to be relevant to the perception of stop place of articulation is
	the second formant {(F2)} transition. This article describes an empirical
	phenomenon--the locus equations--that describes the relationship
	between the F2 of a vowel and the F2 measured at the onset of a consonant-vowel
	{(CV)} transition. These variables, F2 onset and F2 vowel within
	a given place category, are consistently and robustly linearly correlated
	across diverse speakers and languages, and even under perturbation
	conditions as imposed by bite blocks. A functional role for this
	category-level extreme correlation and linearity (the "orderly output
	constraint") is hypothesized based on the notion of an evolutionarily
	conserved auditory-processing strategy. High correlation and linearity
	between critical parameters in the speech signal that help to cue
	place of articulation categories might have evolved to satisfy a
	preadaptation by mammalian auditory systems for representing tightly
	correlated, linearly related components of acoustic signals.},
  issn = {{0140-525X}},
  keywords = {Humans, Phonetics, Speech, Speech Acoustics, Speech Perception},
  owner = {clement},
  shorttitle = {Linear correlates in the speech signal},
  timestamp = {2011.05.01}
}

@INCOLLECTION{Schwartz_PACT_2007,
  author = {{S}chwartz, {J}ean-{L}uc and {B}o{\"e}, {L}ouis-{J}ean and {A}bry,
	{C}hristian},
  title = { {L}inking the {D}ispersion-{F}ocalization {T}heory ({DFT}) and the
	{M}aximum {U}tilization of the {A}vailable {D}istinctive {F}eatures
	({MUAF}) principle in a {P}erception-for-{A}ction-{C}ontrol {T}heory
	({PACT})},
  booktitle = {{E}xperimental {A}pproaches to {P}honology },
  publisher = {{O}xford {U}niversity {P}ress},
  year = {2007},
  editor = {{M}.{J}. {S}ol{\'e}, {P}.{S}. {B}eddor, {M}. {O}hala },
  pages = {104-124 }
}

@INBOOK{Taine_1877,
  chapter = {Acquisition of language by children},
  pages = {20--26},
  title = {Child language: a book of readings},
  publisher = {Englewood Cliffs, NJ: Prentice-Hall. (Original work published in
	1856)},
  year = {1971},
  editor = {Bar-Adon, Aaron and Leopold, Werner F},
  author = {Taine, H.},
  owner = {clement},
  timestamp = {2013.06.25}
}

@ARTICLE{Tenenbaum_2011_grow,
  author = {Tenenbaum, J. B. and Kemp, C. and Griffiths, T. L. and Goodman, N.
	D.},
  title = {How to Grow a Mind: Statistics, Structure, and Abstraction},
  journal = {Science},
  year = {2011},
  volume = {331},
  pages = {1279--1285},
  number = {6022},
  owner = {clement},
  timestamp = {2013.12.30}
}

@ARTICLE{thrun1995exploration,
  author = {Thrun, Sebastian},
  title = {Exploration in active learning},
  journal = {Handbook of Brain Science and Neural Networks},
  year = {1995},
  pages = {381--384},
  owner = {clement},
  publisher = {Citeseer},
  timestamp = {2013.03.31}
}

@ARTICLE{Tomasello2005,
  author = {Michael Tomasello and Malinda Carpenter and Josep Call and Tanya
	Behne and Henrike Moll},
  title = {Understanding and sharing intentions: the origins of cultural cognition},
  journal = {The Behavioral and Brain Sciences},
  year = {2005},
  volume = {28},
  pages = {675--691; discussion 691-735},
  number = {5},
  month = oct,
  note = {{PMID:} 16262930},
  abstract = {We propose that the crucial difference between human cognition and
	that of other species is the ability to participate with others in
	collaborative activities with shared goals and intentions: shared
	intentionality. Participation in such activities requires not only
	especially powerful forms of intention reading and cultural learning,
	but also a unique motivation to share psychological states with others
	and unique forms of cognitive representation for doing so. The result
	of participating in these activities is species-unique forms of cultural
	cognition and evolution, enabling everything from the creation and
	use of linguistic symbols to the construction of social norms and
	individual beliefs to the establishment of social institutions. In
	support of this proposal we argue and present evidence that great
	apes (and some children with autism) understand the basics of intentional
	action, but they still do not participate in activities involving
	joint intentions and attention (shared intentionality). Human children's
	skills of shared intentionality develop gradually during the first
	14 months of life as two ontogenetic pathways intertwine: (1) the
	general ape line of understanding others as animate, goal-directed,
	and intentional agents; and (2) a species-unique motivation to share
	emotions, experience, and activities with other persons. The developmental
	outcome is children's ability to construct dialogic cognitive representations,
	which enable them to participate in earnest in the collectivity that
	is human cognition.},
  doi = {10.1017/S0140525X05000129},
  issn = {{0140-525X}},
  keywords = {Aging, Animals, Autistic Disorder, Cognition, Cooperative Behavior,
	Culture, Evolution, Goals, Humans, Primates, Social Behavior, Volition},
  shorttitle = {Understanding and sharing intentions}
}

@ARTICLE{Tourville2008,
  author = {Jason A. Tourville and Kevin J. Reilly and Frank H. Guenther},
  title = {Neural mechanisms underlying auditory feedback control of speech},
  journal = {{NeuroImage}},
  year = {2008},
  volume = {39},
  pages = {1429--1443},
  number = {3},
  month = feb,
  abstract = {The neural substrates underlying auditory feedback control of speech
	were investigated using a combination of functional magnetic resonance
	imaging {(fMRI)} and computational modeling. Neural responses were
	measured while subjects spoke monosyllabic words under two conditions:
	(i) normal auditory feedback of their speech and (ii) auditory feedback
	in which the first formant frequency of their speech was unexpectedly
	shifted in real time. Acoustic measurements showed compensation to
	the shift within approximately 136 ms of onset. Neuroimaging revealed
	increased activity in bilateral superior temporal cortex during shifted
	feedback, indicative of neurons coding mismatches between expected
	and actual auditory signals, as well as right prefrontal and Rolandic
	cortical activity. Structural equation modeling revealed increased
	influence of bilateral auditory cortical areas on right frontal areas
	during shifted speech, indicating that projections from auditory
	error cells in posterior superior temporal cortex to motor correction
	cells in right frontal cortex mediate auditory feedback control of
	speech.},
  doi = {10.1016/j.neuroimage.2007.09.054},
  issn = {1053-8119},
  keywords = {Auditory feedback control, Effective connectivity, Functional magnetic
	resonance imaging, Neural modeling, Speech production, Structural
	equation modeling}
}

@ARTICLE{Triesch_2013_Imitation,
  author = {Triesch, Jochen},
  title = {Imitation Learning Based on an Intrinsic Motivation Mechanism for
	Efficient Coding},
  journal = {Frontiers in Psychology},
  year = {2013},
  volume = {4},
  number = {800},
  abstract = {A hypothesis regarding the development of imitation learning is presented
	that is rooted in intrinsic motivations. It is derived from a recently
	proposed form of intrinsically motivated learning (IML) for efficient
	coding in active perception, wherein an agent learns to perform actions
	with its sense organs to facilitate efficient encoding of the sensory
	data. To this end, actions of the sense organs that improve the encoding
	of the sensory data trigger an internally generated reinforcement
	signal. Here it is argued that the same IML mechanism might also
	support the development of imitation when general actions beyond
	those of the sense organs are considered: The learner first observes
	a tutor performing a behavior and learns a model of the the behavior's
	sensory consequences. The learner then acts itself and receives an
	internally generated reinforcement signal reflecting how well the
	sensory consequences of its own behavior are encoded by the sensory
	model. Actions that are more similar to those of the tutor will lead
	to sensory signals that are easier to encode and produce a higher
	reinforcement signal. Through this, the learner's behavior is progressively
	tuned to make the sensory consequences of its actions match the learned
	sensory model. I discuss this mechanism in the context of human language
	acquisition and bird song learning where similar ideas have been
	proposed. The suggested mechanism also offers an account for the
	development of mirror neurons and makes a number of predictions.
	Overall, it establishes a connection between principles of efficient
	coding, intrinsic motivations and imitation.},
  doi = {10.3389/fpsyg.2013.00800},
  issn = {1664-1078},
  owner = {clement},
  timestamp = {2013.12.30},
  url = {http://www.frontiersin.org/cognitive_science/10.3389/fpsyg.2013.00800/abstract}
}

@ARTICLE{Vallee1994,
  author = {Vall{\'e}e, N.},
  title = {{Syst{\`e}mes vocaliques: de la typologie aux pr{\'e}dictions}},
  journal = {Grenoble, Universit{\'e} Stendhal: Th{\`e}se de Doctorat en Sciences
	du Langage},
  year = {1994},
  owner = {clement},
  timestamp = {2010.07.22}
}

@INCOLLECTION{Vallee2009,
  author = {Vall{\'e}e, N. and Rossato, S. and Rousset, I.},
  title = {Favoured syllabic patterns in the world's languages and sensorimotor
	constraints},
  booktitle = {Approaches to phonological complexity},
  publisher = {Mouton de Gruyter},
  year = {2009},
  editor = {F. Pellegrino and E. Marsico and I. Chitoran and C. Coupe },
  pages = {111--139},
  address = {Berlin},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@BOOK{varela1991embodied,
  title = {The embodied mind: Cognitive science and human experience},
  publisher = {The MIT Press},
  year = {1991},
  author = {Varela, Franscisco J and Thompson, Evan T and Rosch, Eleanor},
  owner = {clement},
  timestamp = {2013.12.30}
}

@CONFERENCE{Vilain99,
  author = {Vilain, A. and Abry, C. and Badin, P. and Brosda, S.},
  title = {{From idiosyncratic pure frames to variegated babbling: Evidence
	from articulatory modelling}},
  booktitle = {Proceedings of the 14th International Congress of Phonetic Sciences},
  year = {1999},
  volume = {3},
  pages = {2497--2500},
  owner = {clement},
  timestamp = {2010.06.18}
}

@BOOK{Vilain2011,
  title = {Primate Communication and Human Language: Vocalisation, gestures,
	imitation and deixis in humans and non-humans},
  publisher = {John Benjamins Publishing Company},
  year = {2011},
  author = {Dr. Anne Vilain and {Jean-Luc} Schwartz and Prof. Christian Abry
	and Dr. Jacques Vauclair},
  month = feb,
  isbn = {9027204543},
  owner = {clement},
  shorttitle = {Primate Communication and Human Language},
  timestamp = {2011.01.19}
}

@INCOLLECTION{Volterra2005,
  author = {Volterra, V. and Caselli, M. C. and Capirci, O. and Pizzuto, E.},
  title = {Gesture and the emergence and development of language},
  booktitle = {Beyond nature-nurture: Essays in honor of Elizabeth Bates},
  publisher = {Lawrence Erlbaum Associates},
  year = {2005},
  editor = {M. Tomasello and D. Slobin},
  pages = {3--40},
  address = {Mahwah, N.J.},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

@INPROCEEDINGS{Warlaumont_2013_ICDL,
  author = {Warlaumont, A.S.},
  title = {Salience-based reinforcement of a spiking neural network leads to
	increased syllable production},
  booktitle = {Development and Learning and Epigenetic Robotics (ICDL), 2013 IEEE
	International Conference on},
  year = {2013},
  pages = {1-6},
  doi = {10.1109/DevLrn.2012.6400842},
  keywords = {digital simulation;natural language processing;neural nets;canonical
	babbling development;human listener;mature-sounding syllables;motor
	neurons;reinforced vocalization;spike timing dependent plasticity;spiking
	neural network model;synthesized vocalizations;vocal tract simulator;Biological
	neural networks;Brain modeling;Computational modeling;Humans;Muscles;Neurons;Production},
  owner = {clement},
  timestamp = {2013.10.04}
}

@INPROCEEDINGS{Warlaumont_2012_ICDL,
  author = {Warlaumont, A.S.},
  title = {A spiking neural network model of canonical babbling development},
  booktitle = {Development and Learning and Epigenetic Robotics (ICDL), 2012 IEEE
	International Conference on},
  year = {2012},
  pages = {1-6},
  doi = {10.1109/DevLrn.2012.6400842},
  keywords = {digital simulation;natural language processing;neural nets;canonical
	babbling development;human listener;mature-sounding syllables;motor
	neurons;reinforced vocalization;spike timing dependent plasticity;spiking
	neural network model;synthesized vocalizations;vocal tract simulator;Biological
	neural networks;Brain modeling;Computational modeling;Humans;Muscles;Neurons;Production},
  owner = {clement},
  timestamp = {2013.10.04}
}

@ARTICLE{Warlaumont_2013_NN,
  author = {Warlaumont, A. S},
  title = {Prespeech motor learning in a neural network using reinforcement},
  journal = {Neural Networks},
  year = {2013},
  volume = {38},
  pages = {64--95},
  owner = {clement},
  timestamp = {2013.10.04}
}

@ARTICLE{Watkins2003,
  author = {K. E. Watkins and A. P. Strafella and T. Paus},
  title = {Seeing and hearing speech excites the motor system involved in speech
	production},
  journal = {Neuropsychologia},
  year = {2003},
  volume = {41},
  pages = {989--994},
  number = {8},
  abstract = {The perception of action is associated with increased activity in
	motor regions, implicating such regions in the recognition, understanding
	and imitation of actions. We examined the possibility that perception
	of speech, both auditory and visual, would also result in changes
	in the excitability of the motor system underlying speech production.
	Transcranial magnetic stimulation was applied to the face area of
	primary motor cortex to elicit motor-evoked potentials in the lip
	muscles. The size of the motor-evoked potentials was compared under
	the following conditions: listening to speech, listening to non-verbal
	sounds, viewing speech-related lip movements, and viewing eye and
	brow movements. Compared to control conditions, listening to and
	viewing speech enhanced the size of the motor-evoked potential. This
	effect was only seen in response to stimulation of the left hemisphere;
	stimulation of the right hemisphere produced no changes in motor-evoked
	potentials in any of the conditions. In a control experiment, the
	size of the motor-evoked potentials elicited in the muscles of the
	right hand did not differ among conditions, suggesting that speech-related
	changes in excitability are specific to the lip muscles. These results
	provide evidence that both auditory and visual speech perception
	facilitate the excitability of the motor system involved in speech
	production.},
  doi = {10.1016/S0028-3932(02)00316-0},
  issn = {0028-3932},
  keywords = {Hemispheric asymmetry, Motor-evoked potentials, Motor theory of speech
	perception, Orbicularis oris, Primary motor cortex, Transcranial
	magnetic stimulation}
}

@ARTICLE{Weng04,
  author = {Weng, J.},
  title = {Developmental robotics: Theory and experiments},
  journal = {Int. J. Humanoid Robotics},
  year = {2004},
  volume = {1},
  pages = {199-236},
  number = {2},
  owner = {clement},
  timestamp = {2012.06.30}
}

@ARTICLE{Wilson2004,
  author = {Wilson, S.M. and Saygin, A.P. and Sereno, M.I. and Iacoboni, M.},
  title = {{Listening to speech activates motor areas involved in speech production}},
  journal = {Nature Neuroscience},
  year = {2004},
  volume = {7},
  pages = {701--702},
  number = {7},
  owner = {clement},
  publisher = {New York, NY: Nature America Inc., c1998-},
  timestamp = {2010.08.06}
}

@ARTICLE{Wolpert1998,
  author = {D. M. Wolpert and M. Kawato},
  title = {Multiple paired forward and inverse models for motor control},
  journal = {Neural Networks},
  year = {1998},
  volume = {11},
  pages = {1317--1329},
  number = {7-8},
  month = oct,
  abstract = {Humans demonstrate a remarkable ability to generate accurate and appropriate
	motor behavior under many different and often uncertain environmental
	conditions. In this paper, we propose a modular approach to such
	motor learning and control. We review the behavioral evidence and
	benefits of modularity, and propose a new architecture based on multiple
	pairs of inverse (controller) and forward (predictor) models. Within
	each pair, the inverse and forward models are tightly coupled both
	during their acquisition, through motor learning, and use, during
	which the forward models determine the contribution of each inverse
	model's output to the final motor command. This architecture can
	simultaneously learn the multiple inverse models necessary for control
	as well as how to select the inverse models appropriate for a given
	environment. Finally, we describe specific predictions of the model,
	which can be tested experimentally.},
  doi = {10.1016/S0893-6080(98)00066-5},
  issn = {0893-6080},
  keywords = {Contextual prediction, Internal models, Modularity, Motor control,
	Motor learning}
}

@ARTICLE{Wolpert1995,
  author = {{DM} Wolpert and Z Ghahramani and {MI} Jordan},
  title = {An internal model for sensorimotor integration},
  journal = {Science},
  year = {1995},
  volume = {269},
  pages = {1880--1882},
  number = {5232},
  month = sep,
  abstract = {On the basis of computational studies it has been proposed that the
	central nervous system internally simulates the dynamic behavior
	of the motor system in planning, control, and learning; the existence
	and use of such an internal model is still under debate. A sensorimotor
	integration task was investigated in which participants estimated
	the location of one of their hands at the end of movements made in
	the dark and under externally imposed forces. The temporal propagation
	of errors in this task was analyzed within the theoretical framework
	of optimal state estimation. These results provide direct support
	for the existence of an internal model.},
  doi = {10.1126/science.7569931}
}

@BOOK{Bessiere2008,
  title = {Probabilistic Reasoning and Decision Making in Sensory-Motor Systems},
  publisher = {Springer-Verlag},
  year = {2008},
  editor = {Pierre Bessi{\`e}re and Christian Laugier and Roland Siegwart},
  volume = {46},
  series = {Springer Tracts in Advanced Robotics},
  address = {Berlin},
  __markedentry = {[clement:]},
  owner = {clement},
  timestamp = {2012.09.19}
}

